"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Software Engineering based Cost Reduction Techniques for Different Testing Models","Y. M. Roopa; B. Yoshitha","Department of Computer Science and Engineering, Institute of Aeronautical Engineering, Hyderabad; Department of Computer Science and Engineering, Institute of Aeronautical Engineering, Hyderabad","2019 3rd International conference on Electronics, Communication and Aerospace Technology (ICECA)","2 Sep 2019","2019","","","350","354","Software engineering holds a major area for software testing which helps in the minimization of software costs, reduction of errors and overall maintenance. Software testing can be simplified to encompass it as validation and verification. Testing is a methodology of finding out errors in any specific developed program which do not cause any further bugs or interrupt and results in the smooth running of product. Various research papers are available already but still testing is one of the most practiced methodology for assessing the quality of the product. Testing is carried in different wheel of cycle. Software testing more adequately provides rapid development, reduced complexity in digital systems, which includes behavioral models.This paper discusses different software strategies such as unit testing, validation testing and techniques like white box technique, grey box testing and black box testing for object-oriented results. This paper also aims to discuss various existing testing techniques as well as improved techniques and also display the views of software testing community in general.","","978-1-7281-0167-5","10.1109/ICECA.2019.8822134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822134","White box testing;black box testing;grey box testing;Software testing;process model;testing techniques","Software;Software testing;Conferences;Security;Tools;Aerospace electronics","cost reduction;minimisation;program debugging;program testing;software maintenance;software quality","software costs;unit testing;validation testing;grey box testing;black box testing;software engineering;cost reduction techniques;software testing;minimization;software maintenance;bugs;product quality;digital systems;behavioral models;white box technique;object-oriented","","2","","13","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"Coverage-Based Reduction of Test Execution Time: Lessons from a Very Large Industrial Project","T. Bach; A. Andrzejak; R. Pannemans","Institute of Computer Science, Heidelberg University, Heidelberg, Germany; Institute of Computer Science, Heidelberg University, Heidelberg, Germany; SAP SE, Walldorf, Germany","2017 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","17 Apr 2017","2017","","","3","12","There exist several coverage-based approaches to reduce time and resource costs of test execution. While these methods are well-investigated and evaluated for smaller to medium-size projects, we faced several challenges in applying them in the context of a very large industrial software project, namely SAP HANA. These issues include: varying effectiveness of algorithms for test case selection/prioritization, large amounts of shared (non-specific) coverage between different tests, high redundancy of coverage data, and randomness of test results (i.e. flaky tests), as well as of the coverage data (e.g. due to concurrency issues). We address these issues by several approaches. First, our study shows that compared to standard algorithms, so-called overlap-aware solvers can achieve up to 50% higher code coverage in a fixed time budget, significantly increasing the effectiveness of test case prioritization and selection. We also detected in our project high redundancy of line coverage data (up to 97%), providing opportunities for data size reduction. Finally, we show that removal of coverage shared by tests can significantly increase test specificity. Our analysis and approaches can help to narrow the gap between research and practice in context of coverage-based testing approaches, especially in case of very large software projects.","","978-1-5090-6676-6","10.1109/ICSTW.2017.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899023","coverage;test case selection;test case prioritization;test specificty;large real world project","Testing;Software;Redundancy;Runtime;Context;Optimization;Heuristic algorithms","data reduction;program testing;project management;redundancy;software cost estimation;software development management","coverage-based testing;data size reduction;line coverage data;fixed time budget;overlap-aware solvers;coverage data redundancy;test case prioritization;test case selection;SAP HANA;very large industrial software project;resource cost reduction;time cost reduction;test execution time reduction;coverage-based reduction","","7","","21","IEEE","17 Apr 2017","","","IEEE","IEEE Conferences"
"Effects of an Economic Approach for Test Case Selection and Reduction for a Large Industrial Project","T. Bach; R. Pannemans; S. Schwedes","Institute of Computer Science, Heidelberg University, Heidelberg, Germany; SAP SE, Dietmar-Hopp-Allee, Walldorf, Germany; SAP SE, Dietmar-Hopp-Allee, Walldorf, Germany","2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","19 Jul 2018","2018","","","374","379","Extensive testing in large projects can lead to tremendous test costs with superlinear growth over time. Researchers have proposed several techniques to tackle this problem. However, the practical effects of these techniques on the asymptotic behaviour of test costs growth in large industrial software projects remains poorly characterized. We introduce and analyse a fixed time budget for test executions for SAP HANA, a large industrial project. Our approach assigns a global fixed time budget to several components. Each component can only execute tests within its budget, which can change only by transfers from other components. This limits the number of test executions for each test run to a constant, thus reducing the asymptotic growth of test costs. Budget transfers and test optimizations adhere to balances between value and costs, thus creating an economic environment for test case selection and reduction. Specifically, this creates incentives to remove unnecessary tests and to optimize test execution times. For SAP HANA, our approach leads to effective test case selection and reduction, and reduces test execution times by 105 years in four months with a negligible effect on quality. The trade-off between runtime savings and failure detection is 1.83 years per failure.","","978-1-5386-6352-3","10.1109/ICSTW.2018.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411779","test costs growth problem;test case selection;test suite reduction;large industrial software project;effect evaluation","Testing;Runtime;Software;Economics;Hardware;Manuals;Conferences","integrated circuit testing;optimisation;program testing","SAP HANA;global fixed time budget;test executions;asymptotic growth;budget transfers;test optimizations;test execution times;superlinear growth;test costs growth;industrial software projects;test case selection;time 105.0 year;time 4.0 month;time 1.83 year","","2","","9","IEEE","19 Jul 2018","","","IEEE","IEEE Conferences"
"Software Testing: Cost Reduction in Industry 4.0","K. J. Valle-Gómez; P. Delgado-Pérez; I. Medina-Bulo; J. Magallanes-Fernández","University of Cadiz, Puerto Real, Spain; University of Cadiz, Puerto Real, Spain; University of Cadiz, Puerto Real, Spain; University of Cadiz, Puerto Real, Spain","2019 IEEE/ACM 14th International Workshop on Automation of Software Test (AST)","2 Sep 2019","2019","","","69","70","Industry 4.0 is changing every perspective of production. This new industry requires the evolution of every aspect of the systems faster than ever before. In this situation, validation and verification emerge as a significant phase of the life cycle of software projects. A software failure could result in catastrophic consequences, so it is crucial that all systems work correctly in production. In this work, we present a collaborative project between the University of Cadiz and Navantia. Navantia is a leader shipbuilding Spanish company which develops grand industrial software projects. The objective of this work is to decrease the total cost of these projects by automatizing the software testing phase.","","978-1-7281-2237-3","10.1109/AST.2019.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822082","Industry 4.0;Software Testing;Automatization","Industries;Software;Software testing;C++ languages;Production;Collaboration","cost reduction;production engineering computing;program testing;project management;shipbuilding industry","software testing phase;cost reduction;software failure;catastrophic consequences;industrial software projects;shipbuilding Spanish company;Industry 4.0;University of Cadiz;Navantia company","","1","","10","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"Introducing a Fuzzy Model for Cost Cognizant Software Test Case Prioritization","R. Mukherjee; K. S. Patnaik","Computer Science and Engineering, Birla Institute of Technology, Mesra, Ranchi, India; Computer Science and Engineering, Birla Institute of Technology, Mesra, Ranchi, India","TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)","12 Dec 2019","2019","","","504","509","Testing ensures the delivery of a product in stipulated amount of time. According to Test Case Prioritization (TCP), test cases with higher priority get executed earlier. Enhancing the fault detection rate, capturing high priority requirements, reducing the cost and time of prioritization mechanism are several goals of TCP techniques. In this paper, we have proposed a fuzzy model that quantifies the savings generated by the prioritization mechanism. The model considers the effect of fault detection rate and number of test cases. Our first research question concentrates on implementing this fuzzy model while our second research question explores which technique for prioritization generates how much savings. Analysis of 10 C programs and 6 Siemens programs from Software Infrastructure Repository (SIR) shows that the technique of combining branch coverage and modified condition and decision coverage (MC/DC) yielded 2.01 times savings over non-prioritized test suite. Results also indicated that only branch coverage based TCP yielded 1.26 times savings over non-prioritized test suite. We hope our cost aware fuzzy model and these savings analysis will make test case prioritization more applicable with better planning. As several stages of software development do not have exact calculation of parameters, we realized that building a fuzzy model is of utmost importance.","2159-3450","978-1-7281-1895-6","10.1109/TENCON.2019.8929716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929716","test case;prioritization;cost;fault detection;number of test cases;fuzzy model","Fault detection;Mathematical model;Software;Buildings;Testing;Measurement;Fuzzy logic","program testing;software fault tolerance","cost cognizant software test case prioritization;fault detection rate;high priority requirements;TCP techniques;branch coverage;nonprioritized test suite;cost aware fuzzy model","","1","","23","IEEE","12 Dec 2019","","","IEEE","IEEE Conferences"
"Practical Selective Regression Testing with Effective Redundancy in Interleaved Tests","D. Marijan; M. Liaaen","Simula, Norway; Cisco, Norway","2018 IEEE/ACM 40th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP)","30 Aug 2018","2018","","","153","162","As software systems evolve and change over time, test suites used for checking the correctness of software typically grow larger. Together with size, test suites tend to grow in redundancy. This is especially problematic for complex highly-configurable software domains, as growing the size of test suites significantly impacts the cost of regression testing. In this paper we present a practical approach for reducing ineffective redundancy of regression suites in continuous integration testing (strict constraints on time-efficiency) for highly-configurable software. The main idea of our approach consists in combining coverage based redundancy metrics (test overlap) with historical fault-detection effectiveness of integration tests, to identify ineffective redundancy that is eliminated from a regression test suite. We first apply and evaluate the approach in testing of industrial video conferencing software. We further evaluate the approach using a large set of artificial subjects, in terms of fault-detection effectiveness and timeliness of regression test feedback. We compare the results with an advanced retest-all approach and random test selection. The results show that regression test selection based on coverage and history analysis can: 1) reduce regression test feedback compared to industry practice (up to 39%), 2) reduce test feedback compared to the advanced retest-all approach (up to 45%) without significantly compromising fault-detection effectiveness (less than 0.5% on average), and 3) improve fault detection effectiveness compared to random selection (72% on average).","","978-1-4503-5659-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449246","Test redundancy;selective regression testing;highly configurable software;highly-interleaving tests;test optimization;continuous regression testing","Testing;Redundancy;Software engineering;Industries;Manuals;Software systems","fault diagnosis;program testing;redundancy;regression analysis;software maintenance;teleconferencing","regression test suite;industrial video conferencing software;regression test feedback;random test selection;regression test selection;fault detection effectiveness;practical selective regression testing;interleaved tests;software systems evolve;highly-configurable software domains;practical approach;continuous integration testing;coverage based redundancy metrics;historical fault-detection effectiveness;integration tests","","","","33","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Using memetic algorithms for test case prioritization in model based software testing","F. M. Nejad; R. Akbari; M. M. Dejam","Department of Computer Engineering and IT, Shiraz University of Technology, Shiraz, Iran; Department of Computer Engineering and IT, Shiraz University of Technology, Shiraz, Iran; Shiraz University of Technology, Shiraz, Fars, IR","2016 1st Conference on Swarm Intelligence and Evolutionary Computation (CSIEC)","2 Jun 2016","2016","","","142","147","Building high quality software is one of the main goals in software industry. Software testing is a critical step in confirming the quality of software. Testing is an expensive activity because it consumes about 30% to 50% of all software developing cost. Today much research has been done in generating and prioritizing tests. First, tester should find the most important and critical path in software. They can reduce cost by finding errors and preventing to propagate it in design step. In this paper, a model based testing method is introduced. This method can prioritize tests using activity diagram, control flow graph, genetic and memetic algorithm. Different version of memetic algorithm has been made by stochastic local search, randomize iterative improvement, hill climbing and simulated annealing algorithms. The results show that the using local search methods with genetic algorithm (GA) provide efficiency and produce competitive results in comparison with GA.","","978-1-4673-8737-8","10.1109/CSIEC.2016.7482129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482129","software testing;prioritization;Genetic;Memetic;Stochastic local search;Randomize iterative improvement;Hill climbing;Simulated annealing","Genetic algorithms;Software;Testing;Unified modeling language;Object oriented modeling;Memetics;Algorithm design and analysis","DP industry;genetic algorithms;program testing;search problems;software cost estimation;software quality","memetic algorithms;test case prioritization;model based software testing;high quality software;software industry;software developing cost;software critical path;cost reduction;model based testing method;activity diagram;control flow graph;genetic algorithm;stochastic local search;randomize iterative improvement;hill climbing;simulated annealing algorithms","","4","","22","IEEE","2 Jun 2016","","","IEEE","IEEE Conferences"
"Improving Test Effectiveness Using Test Executions History: An Industrial Experience Report","A. Najafi; W. Shang; P. C. Rigby","Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada","2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)","19 Aug 2019","2019","","","213","222","The cost of software testing has become a burden for software companies in the era of rapid release and continuous integration. Our industrial collaborator Ericsson also faces the challenges of expensive testing processes which are typically part of a complex and specialized testing environment. In order to assist Ericsson with improving the test effectiveness of one of its large subsystems, we adopt test selection and prioritization approaches based on test execution history from prior research. By adopting and simulating those approaches on six months of testing data from our subject system, we confirm the existence of valuable information in the test execution history. In particular, the association between test failures provide the most value to the test selection and prioritization processes. More importantly, during this exercise, we encountered various challenges that are unseen or undiscussed in prior research. We document the challenges, our solutions and the lessons learned as an experience report. Our experiences can be valuable for other software testing practitioners and researchers who would like to adopt existing test effectiveness improvement approaches into their work environment.","","978-1-7281-1760-7","10.1109/ICSE-SEIP.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804426","Test effectiveness, Test prioritization, Test selection, Industrial experience report","History;Software systems;Software testing;Redundancy;Software engineering","program testing","test executions history;specialized testing environment;test selection;prioritization approaches;test execution history;test failures;prioritization processes;software testing practitioners;Ericsson;test effectiveness improvement approaches","","15","","36","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"On the Industrial Applicability of Augmented Testing: An Empirical Study","M. Nass; E. Alégroth; R. Feldt","SERL Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; SERL Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; SERL Sweden and Software Engineering, Chalmers University of Technology, Gothenburg, Sweden","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","364","371","Testing applications with graphical user Interfaces (GUI) is an important but also a time-consuming task in practice. Tools and frameworks for GUI test automation can make the test execution more efficient and lower the manual labor required for regression testing. However, the test scripts used for automated GUI-based testing still require a substantial development effort and are often reported as sensitive to change, leading to frequent and costly maintenance. The efficiency of development, maintenance, and evolution of such tests are thereby dependent on the readability of scripts and the ease-of-use of test tools/frameworks in which the test scripts are defined. To address these shortcomings in existing state-of-practice techniques, a novel technique referred to as Augmented Testing (AT) has been proposed. AT is defined as testing the System Under Test (SUT) through an Augmented GUI that superimposes information on top of the SUT GUI. The Augmented GUI can provide the user with hints, test data, or other support while also observing and recording the tester's interactions. For this study, a prototype tool, called Scout, has been used that adheres to the AT concept that is evaluated in an industrial empirical study. In the evaluation, quasi-experiments and questionnaire surveys are performed in two workshops, with 12 practitioners from two Swedish companies (Ericsson and Inceptive). Results show that Scout can be used to create equivalent test cases faster, with statistical significance, than creating automated scripts in two popular state-of-practice tools. The study concludes that AT has cost-value benefits, applies to industrial-grade software, and overcomes several deficiencies of state-of-practice GUI testing technologies in terms of ease-of-use.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155725","System Testing;Test Automation;Industrial Case Study;Augmented Testing","Graphical user interfaces;Testing;Tools;Prototypes;Automation;Manuals;Debugging","graphical user interfaces;industrial engineering;program testing","automated GUI-based testing;test scripts;SUT GUI;test data;equivalent test cases;automated scripts;state-of-practice tools;industrial applicability;graphical user interfaces;GUI test automation;test execution;regression testing;GUI testing technologies;augmented GUI;Swedish companies;Ericsson;Inceptive","","2","","19","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Practical Amplification of Condition/Decision Test Coverage by Combinatorial Testing","A. Andrzejak; T. Bach","Institute of Computer Science, Heidelberg University, Germany; Institute of Computer Science, Heidelberg University, Germany","2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","19 Jul 2018","2018","","","341","347","Test suites in complex software projects might grow over time to considerable sizes, incurring high maintenance effort and prolonged execution times. Maintaining their quality and efficiency require pruning of redundancies while increasing, or at least retaining their coverage levels. We propose a lightweight method to tackle these problems with focus on condition/decision coverage (C/D coverage). First, we describe a method to reduce the size of unit tests suites while preserving the degree of their C/D coverage. We then introduce an approach which combines combinatorial testing and input space modeling to further increase the degree of the C/D coverage. Our semi-automated method works even in absence of models or documentation, and it produces a low number of new test cases requiring queries to a test oracle. We also do not use symbolic execution techniques due to their complexity and limited tool availability for some languages. These properties make our approach practically applicable in industrial projects, and simpler to implement. We evaluate our approach on selected examples from SAP HANA, a very large industrial application in C++. We demonstrate that it is possible to generate from integration tests new suites of unit tests with high C/D-coverage but with only few test cases. At the same time, the human effort of creating such suites is moderate.","","978-1-5386-6352-3","10.1109/ICSTW.2018.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411773","Unit Testing;Combinatorial Testing;Input Space Modeling;Test Coverage;Test Suite Minimization","Software;Conferences;Software testing;Documentation;C++ languages","decision making;program testing;project management;software management","condition/decision test coverage;combinatorial testing;complex software projects;coverage levels;lightweight method;unit tests suites;input space modeling;test oracle;industrial projects;integration tests;C/D-coverage","","1","","15","IEEE","19 Jul 2018","","","IEEE","IEEE Conferences"
"A comprehensive review for test case prioritization in Software Engineering","Ashima; G. Shaheamlung; K. Rote","School of Computer Science & Engineering, Lovely Professional University, Phagwara, Punjab; School of Computer Science & Engineering, Lovely Professional University, Phagwara, Punjab; School of Computer Science & Engineering, Lovely Professional University, Phagwara, Punjab","2020 International Conference on Intelligent Engineering and Management (ICIEM)","6 Aug 2020","2020","","","331","336","In the past years, test case prioritization has been improved in the regression testing by the use of effective test cases. The continuous improvement and attention have increased in terms of prioritization algorithm, coverage criteria, measurement, application scenario and the practice concerned. It has focused mainly on Prioritizing and scheduling the test cases. The main purpose of this paper is to study the different prioritization techniques used by various authors in previous years. Regression testing, a type of testing in which is being used as a tool for checking, testing, and up-gradation of software. The test cases of all scheduling and prioritizing are set in the ordered and proper method and as result, this case shows the detection and a maximum number of faults in the software in which the technical faults are traced and detected as the detected faults. Through the fault detection of the test case, it reduces the test case and minimizes the execution cost. As a result, this method shows the running of the test case at a higher priority in order to reduce and minimize the cost, time and effort of software testing.","","978-1-7281-4097-1","10.1109/ICIEM48762.2020.9160217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160217","Regression Testing;Test case prioritization;Prioritization algorithm","Software;Optimization;Software testing;Computer science;Job shop scheduling;Fault detection","program testing;regression analysis;software engineering","test case prioritization;regression testing;software testing;technical fault detection","","2","","26","IEEE","6 Aug 2020","","","IEEE","IEEE Conferences"
"Assessing the Test Suite of a Large System Based on Code Coverage, Efficiency and Uniqueness","L. Vidács; F. Horváth; D. Tengeri; Á. Beszédes","MTA-SZTE Research Group on Artificial Intelligence, University of Szeged, Szeged, Hungary; Department of Software Engineering, University of Szeged, Szeged, Hungary; Department of Software Engineering, University of Szeged, Szeged, Hungary; Department of Software Engineering, University of Szeged, Szeged, Hungary","2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","23 May 2016","2016","2","","13","16","Regression test suites of evolving software systems play a key role in maintaining software quality throughout continuous changes. They need to be effective (in terms of detecting faults and helping their localization) and efficient (optimally sized and without redundancy) at the same time. However, test suite quality attributes are usually difficult to formalize and measure. In this paper, we rely on a recent approach for test suite assessment and improvement that utilizes code coverage information, but at a more detailed level, hence it adds further evaluation aspects derived from the coverage. The basic idea of the method is to decompose the test suite and the program code into coherent logical groups which are easier to analyze and understand. Several metrics are then computed from code coverage information to characterize the test suite and its constituents. We extend our previous study and employ derived coverage metrics (which express efficiency and uniqueness) to analyze the test suite of a large scale industrial open source system containing 27 000 test cases.","","978-1-5090-1855-0","10.1109/SANER.2016.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476754","code coverage;regression testing;test suite evaluation;test suite quality;test efficiency;test metrics","Measurement;Testing;Cascading style sheets;Systematics;Heating;Software quality","program testing;software maintenance;software metrics;software quality","software systems;software quality maintenance;test suite quality attributes;test suite assessment;code coverage information;program code;coherent logical groups;coverage metrics;large scale industrial open source system;regression test suites","","2","2","13","IEEE","23 May 2016","","","IEEE","IEEE Conferences"
"An Empirical Study on the Spreading of Fault Revealing Test Cases in Prioritized Suites","W. N. M. Torres; E. L. G. Alves; P. D. L. Machado","Software Practices Laboratory, Campina Grande, Brazil; Software Practices Laboratory, Campina Grande, Brazil; Software Practices Laboratory, Campina Grande, Brazil","2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)","9 Jul 2019","2019","1","","129","138","Code edits are very common during software development. Specially for agile development, these edits need constant validation to avoid functionality regression. In this context, regression test suites are often used. However, regression testing can be very costly. Test case prioritization (TCP) techniques try to reduce this burden by reordering the tests of a given suite aiming at fastening the achievement of a certain testing goal. The literature presents a great number of TCP techniques. Most of the work related to prioritization evaluate the performance of TCP techniques by calculating the rate of test cases that fail per fault (the APFD metric). However, other aspects should be considered when evaluating prioritization results. For instance, the ability to reduce the spreading of failing test cases, since a better grouping often provides more information regarding faults. This paper presents an empirical investigation for evaluating the performance of a set of prioritization techniques comparing APFD and spreading results. Our results show that prioritization techniques generate different APFD and spreading results, being total-statement prioritization the one with the lowest spreading.","0730-3157","978-1-7281-2607-4","10.1109/COMPSAC.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754416","prioritization;test case;metric;evaluation","Measurement;Fault detection;Software;Testing;Mathematical model;Guidelines;Conferences","program testing;software fault tolerance","code edits;software development;agile development;functionality regression;regression test suites;regression testing;test case prioritization techniques;TCP techniques;spreading results;total-statement prioritization;fault revealing test cases;prioritized suites","","1","","34","IEEE","9 Jul 2019","","","IEEE","IEEE Conferences"
"Abstract Test Case Prioritization Using Repeated Small-Strength Level-Combination Coverage","R. Huang; W. Sun; T. Y. Chen; D. Towey; J. Chen; W. Zong; Y. Zhou","School of Computer Science and Communication Engineering; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, Australia; School of Computer Science, University of Nottingham Ningbo China, Ningbo, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China","IEEE Transactions on Reliability","3 Mar 2020","2020","69","1","349","372","Abstract test cases (ATCs) have been widely used in practice, including in combinatorial testing and in software product line testing. When constructing a set of ATCs, due to limited testing resources in practice (e.g., in regression testing), test case prioritization (TCP) has been proposed to improve the testing quality, aiming at ordering test cases to increase the speed with which faults are detected. One intuitive and extensively studied TCP technique for ATCs is λ-wise Level-combination Coverage based Prioritization (λLCP), a static, black-box prioritization technique that only uses the ATC information to guide the prioritization process. A challenge facing λLCP, however, is the necessity for the selection of the fixed prioritization strength λ before testing-testers need to choose an appropriate λ value before testing begins. Choosing higher λ values may improve the testing effectiveness of λLCP (e.g., by finding faults faster), but may reduce the testing efficiency (by incurring additional prioritization costs). Conversely, choosing lower λ values may improve the efficiency, but may also reduce the effectiveness. In this paper, we propose a new family of λLCP techniques, Repeated Small-strength Level-combination Coverage-based Prioritization (RSLCP), that repeatedly achieves the full combination coverage at lower strengths. RSLCP maintains λLCP's advantages of being static and black box, but avoids the challenge of prioritization strength selection. We have performed an empirical study involving five different versions of each of five C programs. Compared with λLCP, and Incremental-strength LCP (ILCP), our results show that RSLCP could provide a good tradeoff between testing effectiveness and efficiency. Our results also show that RSLCP is more effective and efficient than two popular techniques of Similarity-based Prioritization (SP). In addition, the results of empirical studies also show that RSLCP can remain robust over multiple system releases.","1558-1721","","10.1109/TR.2019.2908068","National Natural Science Foundation of China(grant numbers:61502205,61872167,71471092,U1836116); Senior Personnel Scientific Research Foundation of Jiangsu University(grant numbers:14JDG039); Ningbo Municipal Bureau of Science and Technology(grant numbers:2014A35006); Young Backbone Teacher Cultivation Project of Jiangsu University; University of Nottingham Ningbo China; International Doctoral Innovation Centre; Ningbo Municipal Bureau of Education; Ningbo Municipal Bureau of Science and Technology; University Of Nottingham; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705674","Abstract test case;level-combination coverage;regression testing;software testing;test case prioritization","Software testing;Fault detection;Regression analysis;Level set","program testing;regression analysis","abstract test case prioritization;ATCs;combinatorial testing;software product line testing;regression testing;TCP technique;black-box prioritization technique;λLCP techniques;RSLCP;prioritization strength selection;similarity-based prioritization;repeated small-strength level-combination coverage-based prioritization;λ-wise level-combination coverage based prioritization;incremental-strength LCP;ILCP","","7","","66","IEEE","3 May 2019","","","IEEE","IEEE Journals"
"Test Re-Prioritization in Continuous Testing Environments","Y. Zhu; E. Shihab; P. C. Rigby","Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada","2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)","11 Nov 2018","2018","","","69","79","New changes are constantly and concurrently being made to large software systems. In modern continuous integration and deployment environments, each change requires a set of tests to be run. This volume of tests leads to multiple test requests being made simultaneously, which warrant prioritization of such requests. Previous work on test prioritization schedules queued tests at set time intervals. However, after a test has been scheduled it will never be reprioritized even if new higher risk tests arrive. Furthermore, as each test finishes, new information is available which could be used to reprioritize tests. In this work, we use the conditional failure probability among tests to reprioritize tests after each test run. This means that tests can be reprioritized hundreds of times as they wait to be run. Our approach is scalable because we do not depend on static analysis or coverage measures and simply prioritize tests based on their co-failure probability distributions. We named this approach CODYNAQ and in particular, we propose three prioritization variants called CODYNAQSINGLE, CODYNAQDOUBLE and CODYNAQFLEXI. We evaluate our approach on two data sets, CHROME and Google testing data. We find that our co-failure dynamic re-prioritization approach, CODYNAQ, outperforms the default order, FIFOBASELINE, finding the first failure and all failures for a change request by 31% and 62% faster, respectively. CODYNAQ also outperforms GOOGLETCP by finding the first failure 27% faster and all failures 62% faster.","2576-3148","978-1-5386-7870-1","10.1109/ICSME.2018.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530018","Regression testing;Test minimization;Dynamic test prioritization;Test dependency;Continuous testing;Continuous integration","Testing;Google;Software engineering;Computer science;Schedules;Software;Companies","program testing;scheduling","change request;continuous testing environments;software systems;multiple test requests;test prioritization schedules;set time intervals;conditional failure probability;static analysis;coverage measures;Google testing data;cofailure dynamic reprioritization approach;CODYNAQ approach;cofailure probability distributions","","19","","22","IEEE","11 Nov 2018","","","IEEE","IEEE Conferences"
"Speeding up Mutation Testing via Regression Test Selection: An Extensive Study","L. Chen; L. Zhang","Computer Science Department, The University of Texas at Dallas; Computer Science Department, The University of Texas at Dallas","2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)","28 May 2018","2018","","","58","69","Mutation testing is one of the most powerful methodologies to evaluate the quality of test suites, and has also been demonstrated to be effective for various other testing and debugging problems, e.g., test generation, fault localization, and program repair. However, despite various mutation testing optimization techniques, mutation testing is still notoriously time-consuming. Regression Testing Selection (RTS) has been widely used to speed up regression testing. Given a new program revision, RTS techniques only select and rerun the tests that may be affected by code changes, since the other tests should have the same results as the prior revision. To date, various practical RTS tools have been developed and used in practice. Intuitively, such RTS tools may be directly used to speed up mutation testing of evolving software systems, since we can simply recollect the mutation testing results of the affected tests while directly obtaining the mutation testing results for the other tests from the prior revision. However, to our knowledge, there is no such study. Therefore, in this paper, we perform the first extensive study (using 1513 revisions of 20 real-world GitHub Java projects, totalling 83.26 Million LoC) on the effectiveness and efficiency of various RTS techniques in speeding up mutation testing. Our study results demonstrate that both file-level static and dynamic RTS can achieve precise and efficient mutation testing, providing practical guidelines for developers.","","978-1-5386-5012-7","10.1109/ICST.2018.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367036","Mutation Testing;Regression Testing;Regression Test Selection;Static Analysis;Dynamic Analysis","Tools;Java;Software;Debugging;Test pattern generators;Maintenance engineering","Java;optimisation;program debugging;program testing;regression analysis","regression test Selection;test suites;test generation;mutation testing optimization techniques;regression testing;mutation testing;fault localization;program repair;regression testing selection;RTS","","16","","69","IEEE","28 May 2018","","","IEEE","IEEE Conferences"
"[Journal First] Journal First Presentation of an Experience Report on Applying Software Testing Academic Results in Industry: We Need Usable Automated Test Generation","A. Arcuri","Fac. of Technol., Westerdals Oslo ACT, Oslo, Norway","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","2 Sep 2018","2018","","","1065","1065","What is the impact of software engineering research on current practices in industry? In this paper, I report on my direct experience as a PhD/post-doc working in software engineering research projects, and then spending the following five years as an engineer in two different companies (the first one being the same I worked in collaboration with during my post-doc). Given a background in software engineering research, what cutting-edge techniques and tools from academia did I use in my daily work when developing and testing the systems of these companies? Regarding validation and verification (my main area of research), the answer is rather short: as far as I can tell, only FindBugs. In this paper, I report on why this was the case, and discuss all the challenging, complex open problems we face in industry and which somehow are ""neglected"" in the academic circles. In particular, I will first discuss what actual tools I could use in my daily work, such as JaCoCo and Selenium. Then, I will discuss the main open problems I faced, particularly related to environment simulators, unit and web testing. After that, popular topics in academia are presented, such as UML, regression and mutation testing. Their lack of impact on the type of projects I worked on in industry is then discussed. Finally, from this industrial experience, I provide my opinions about how this situation can be improved, in particular related to how academics are evaluated, and advocate for a greater involvement into open-source projects.","1558-1225","978-1-4503-5638-1","10.1145/3180155.3182555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453187","Industry;Practice;Technology Transfer;Impact;Applied Research","Software engineering;Industries;Software testing;Test pattern generators;Companies;Tools","automatic test pattern generation;automatic test software;program testing;public domain software;software engineering","cutting-edge techniques;daily work;complex open problems;main open problems;web testing;regression;mutation testing;industrial experience;experience report;usable automated test generation;direct experience;PhD/post-doc;software engineering research projects;time 5.0 year","","2","","","","2 Sep 2018","","","IEEE","IEEE Conferences"
"System-Level Test Case Prioritization Using Machine Learning","R. Lachmann; S. Schulze; M. Nieke; C. Seidl; I. Schaefer","Technische Universität Braunschweig, Germany; Technische Universität Braunschweig, Germany; Technische Universität Braunschweig, Germany; Technische Universität Braunschweig, Germany; Otto-von-Guericke Universität Magdeburg, Germany","2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)","2 Feb 2017","2016","","","361","368","Regression testing is the common task of retesting software that has been changed or extended (e.g., by new features) during software evolution. As retesting the whole program is not feasible with reasonable time and cost, usually only a subset of all test cases is executed for regression testing, e.g., by executing test cases according to test case prioritization. Although a vast amount of methods for test case prioritization exist, they mostly require access to source code (i.e., white-box). However, in industrial practice, system-level testing is an important task that usually grants no access to source code (i.e., black-box). Hence, for an effective regression testing process, other information has to be employed. In this paper, we introduce a novel technique for test case prioritization for manual system-level regression testing based on supervised machine learning. Our approach considers black-box meta-data, such as test case history, as well as natural language test case descriptions for prioritization. We use the machine learning algorithm SVM Rank to evaluate our approach by means of two subject systems and measure the prioritization quality. Our results imply that our technique improves the failure detection rate significantly compared to a random order. In addition, we are able to outperform a test case order given by a test expert. Moreover, using natural language descriptions improves the failure finding rate.","","978-1-5090-6167-9","10.1109/ICMLA.2016.0065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838169","System-Level Testing;Black-Box Testing;Test Case Prioritization;Supervised Machine Learning","Testing;Support vector machines;Software;Training data;Natural languages;Dictionaries;Training","learning (artificial intelligence);natural languages;program testing;regression analysis;source code (software)","failure finding rate;natural language descriptions;test expert;random order;failure detection rate;prioritization quality;SVM rank;natural language test case descriptions;test case history;black-box meta-data;supervised machine learning;industrial practice;source code;test case prioritization;software evolution;retesting software;regression testing;system-level test case prioritization","","35","","34","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Scalable Approaches for Test Suite Reduction","E. Cruciani; B. Miranda; R. Verdecchia; A. Bertolino","Gran Sasso Science Institute | L’ Aquila, Italy; Federal University of Pernambuco | Recife, Brazil; Vrije Universiteit Amsterdam | Amsterdam, The Netherlands; ISTI - Consiglio Nazionale delle Ricerche | Pisa, Italy","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","26 Aug 2019","2019","","","419","429","Test suite reduction approaches aim at decreasing software regression testing costs by selecting a representative subset from large-size test suites. Most existing techniques are too expensive for handling modern massive systems and moreover depend on artifacts, such as code coverage metrics or specification models, that are not commonly available at large scale. We present a family of novel very efficient approaches for similarity-based test suite reduction that apply algorithms borrowed from the big data domain together with smart heuristics for finding an evenly spread subset of test cases. The approaches are very general since they only use as input the test cases themselves (test source code or command line input). We evaluate four approaches in a version that selects a fixed budget B of test cases, and also in an adequate version that does the reduction guaranteeing some fixed coverage. The results show that the approaches yield a fault detection loss comparable to state-of-the-art techniques, while providing huge gains in terms of efficiency. When applied to a suite of more than 500K real world test cases, the most efficient of the four approaches could select B test cases (for varying B values) in less than 10 seconds.","1558-1225","978-1-7281-0869-8","10.1109/ICSE.2019.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812048","Clustering;Random projection;Similarity-based testing;Software testing;Test suite reduction","Testing;Big Data;Software;Measurement;Fault detection;Scalability;Clustering algorithms","Big Data;program testing;set theory","similarity-based test suite reduction;evenly spread subset;test source code;B test cases;scalable approaches;test suite reduction approaches;large-size test suites;modern massive systems;code coverage metrics;big data domain;smart heuristics;command line input","","15","","36","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Enhancing Test Case Prioritization in an Industrial Setting with Resource Awareness and Multi-objective Search","S. Wang; S. Ali; T. Yue; Ø. Bakkeli; M. Liaaen","Simula Res. Lab., Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway; Cisco Systems, Oslo, Norway; Cisco Systems, Oslo, Norway","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","23 Mar 2017","2016","","","182","191","Test case prioritization is an essential part of test execution systems for large organizations developing software systems in the context that their software versions are released very frequently. They must be tested on a variety of compatible hardware with different configurations to ensure correct functioning of a software version on a compatible hardware. In practice, test case execution must not only execute cost-effective test cases in an optimal order, but also optimally allocate required test resources, in order to deliver high quality software releases. To optimize the current test execution system for testing software releases developed for Videoconferencing Systems (VCSs) at Cisco, Norway, in this paper, we propose a resource- aware multi-objective optimization solution with a fitness function defined based on four cost-effectiveness measures. In this context, a set of software releases must be tested on a set of compatible VCS hardware (test resources) by executing a set of cost-effective test cases in an optimal order within a given test cycle constrained by maximum allowed time budget and maximum available test resources. We empirically evaluated seven search algorithms regarding their performance and scalability by comparing with the current practice (random ordering (RO)). The results show that the proposed solution with the best search algorithm (i.e., Random-Weighted Genetic Algorithm) improved the current practice by reducing on average 40.6% of time for test resource allocation and test case execution, improved test resource usage on average by 37.9% and fault detection on average by 60%.","","978-1-4503-4205-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883302","Test Case Prioritization;Multi-objective Optimization;Search","Search problems;Software;Classification algorithms;Hardware;Testing;Fault detection;Time measurement","optimisation;program testing;resource allocation;search problems;software cost estimation;software fault tolerance;software quality;teleconferencing;video communication","test case prioritization;resource awareness;multiobjective search;software system development;software versions;cost-effective test execution;optimal test resource allocation;high quality software releases;videoconferencing systems;Cisco;Norway;resource-aware multiobjective optimization;fitness function;cost-effectiveness measures;VCS hardware;search algorithms;improved test resource usage;fault detection","","1","","27","","23 Mar 2017","","","IEEE","IEEE Conferences"
"Improving Data Quality for Regression Test Selection by Reducing Annotation Noise","K. W. Al-Sabbagh; M. Staron; R. Hebig; W. Meding","Chalmers | University of Gothenburg, Gothenburg, Sweden; Chalmers | University of Gothenburg, Gothenburg, Sweden; Chalmers | University of Gothenburg, Gothenburg, Sweden; Ericsson AB","2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","16 Oct 2020","2020","","","191","194","Big data and machine learning models have been increasingly used to support software engineering processes and practices. One example is the use of machine learning models to improve test case selection in continuous integration. However, one of the challenges in building such models is the identification and reduction of noise that often comes in large data. In this paper, we present a noise reduction approach that deals with the problem of contradictory training entries. We empirically evaluate the effectiveness of the approach in the context of selective regression testing. For this purpose, we use a curated training set as input to a tree-based machine learning ensemble and compare the classification precision, recall, and f-score against a non-curated set. Our study shows that using the noise reduction approach on the training instances gives better results in prediction with an improvement of 37% on precision, 70% on recall, and 59% on f-score.","","978-1-7281-9532-2","10.1109/SEAA51224.2020.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226358","Annotation Noise;Regression Testing;Machine Learning Models","Training;Testing;Annotations;Predictive models;Noise reduction;Feature extraction;Dictionaries","learning (artificial intelligence);pattern classification;program testing;regression analysis","annotation noise reduction;tree-based machine;curated training;selective regression testing;contradictory training entries;continuous integration;test case selection;software engineering processes;machine learning models;big data;regression test selection;data quality;noise reduction approach","","1","","12","IEEE","16 Oct 2020","","","IEEE","IEEE Conferences"
"TITAN: Test Suite Optimization for Highly Configurable Software","D. Marijan; M. Liaaen; A. Gotlieb; S. Sen; C. Ieva","Simula Research Laboratory, Norway; Cisco Systems, Norway; Simula Research Laboratory, Norway; Simula Research Laboratory, Norway; Simula Research Laboratory, Norway","2017 IEEE International Conference on Software Testing, Verification and Validation (ICST)","18 May 2017","2017","","","524","531","Exhaustive testing of highly configurable software developed in continuous integration is rarely feasible in practice due to the configuration space of exponential size on the one hand, and strict time constraints on the other. This entails using selective testing techniques to determine the most failure-inducing test cases, conforming to highly-constrained time budget. These challenges have been well recognized by researchers, such that many different techniques have been proposed. In practice, however, there is a lack of efficient tools able to reduce high testing effort, without compromising software quality. In this paper we propose a test suite optimization technology TITAN, which increases the time-and cost-efficiency of testing highly configurable software developed in continuous integration. The technology implements practical test prioritization and minimization techniques, and provides test traceability and visualization for improving the quality of testing. We present the TITAN tool and discuss a set of methodological and technological challenges we have faced during TITAN development. We evaluate TITAN in testing of Cisco's highly configurable software with frequent high quality releases, and demonstrate the benefit of the approach in such a complex industry domain.","","978-1-5090-6031-3","10.1109/ICST.2017.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7928010","Test optimization;test prioritization;highly-configurable software;continuous integration testing","Testing;Optimization;Software;Minimization;Tools;Fault detection;Data models","minimisation;program diagnostics;program testing;program visualisation;software quality","TITAN;test suite optimization;Cisco highly configurable software testing;selective testing;failure-inducing test cases;software quality;test prioritization techniques;test minimization techniques;test traceability;visualization","","11","","28","IEEE","18 May 2017","","","IEEE","IEEE Conferences"
"A novel probabilistic-ABC based boosting model for software defect detection","P. R. Kumar; G. P. S. Varma","Department of CSE, Sir C R R College of engineering, Eluru, India; Sagi Ramakrishnam Raju Engineering College, Bhimavaram, India","2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)","1 Feb 2018","2017","","","1","6","As the development platforms in software technology grow rapidly; the development of software systems has become more and more complex and versatile. It is quite necessary for the software industries to develop software products with good qualities. As the size of the product and development technologies increasing, there is need for identification of software defects at the early stage of development phase. Detection of defects appropriately and accurately measured in the early stage to increase the quality of the product. Software metric can be defined as building blocks of prediction models. The evaluation of software metric is carried out in the design and coding phase prior to actual implementation of the product. Defects are described as a type of conditions that does not satisfy minimum requirement and this can lead to malfunction or unexpected outcomes. The numbers of defects are inversely proportional with the quality which means, on decreasing numbers of defects will result better software quality. Detection of these defects at the early stage of development life cycle will reduce the cost and effort to a great extent. Since decades many researchers have proposed different models for detection of defects in software modules. In this paper we emphasized on defect detection approaches using machine learning scheme to improve true positive rate. Prediction metrics are basically split into two categories, those are: - code metrics and process metrics. In this paper we have designed and implemented a novel defect prediction model using probabilistic ABC based classification model. We compared our model with various defect detection approaches in terms of statistical measures. Experimental results proved that proposed model has high computational detection rate compared to traditional models.","","978-1-5090-3294-5","10.1109/ICIIECS.2017.8276059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276059","Software defects;Machine learning;feature selection models","Software;Predictive models;Computational modeling;Software metrics;Feature extraction;Genetic algorithms","cost reduction;DP industry;learning (artificial intelligence);pattern classification;program testing;software metrics;software quality;statistical analysis","software defect detection;development platforms;software technology;development technologies;early stage;development phase;software metric;prediction models;coding phase;development life cycle;software modules;defect detection approaches;prediction metrics;code metrics;process metrics;probabilistic ABC based classification model;high computational detection rate;traditional models;software system development;software product quality;software defect identification;design phase;probabilistic-ABC based boosting model;software industries;cost reduction;cost reduction;machine learning scheme;true positive rate;defect prediction model;statistical measures","","2","","12","IEEE","1 Feb 2018","","","IEEE","IEEE Conferences"
"A Method for Test Cases Reduction in Web Application Testing Based on User Session","S. Wang; W. Wu; J. Sun","School of Computer Science & Technology, Xi'an University of Posts & Telecommunications, Xi'an, China; School of Computer Science & Technology, Xi'an University of Posts & Telecommunications, Xi'an, China; School of Computer Science & Technology, Xi'an University of Posts & Telecommunications, Xi'an, China","2018 International Conference on Networking and Network Applications (NaNA)","24 Feb 2019","2018","","","378","383","With the development of web application, the internal structure of the web application was more complicated. The software testing method based on user session has been used to verify the quality of web application. However, the amount of real user session data were extremely large. In order to reduce the scale of the test case set for web application testing, we proposed a reduced method of test cases based on user session. First, we cleaned the original log file and identified user session and sorted the user sessions according to the Gini index. Then, we made an “OR” operation on the all user sessions coverage to obtain some user sessions that cover all pages of web application. These user sessions were a set of reduced test cases. Finally, the structure dependency graph of web application was generated according to the user sessions. The PageRank algorithm and the Hamming distance are used to optimize the test cases reduced with the same Gini index. By this means, we obtained the final test cases set for reduction. Through experimental verification, we found that the reduction rate of the test cases reached 85.7% and the fault coverage rate reached 100% by our method. Therefore, the method we proposed in this paper improved effectively the reliability of web application and the effectiveness of software testing and reduced the cost of software testing.","","978-1-5386-8303-3","10.1109/NANA.2018.8648767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648767","user session;Gini index;PageRank algorithm;Hamming distance;test cases reduction","Indexes;Web pages;Software testing;Software;Software reliability","graph theory;Internet;program testing;software fault tolerance","user session data;software testing;test cases reduction;Web application testing;structure dependency graph;PageRank algorithm;Hamming distance;Gini index;software faults","","","","16","IEEE","24 Feb 2019","","","IEEE","IEEE Conferences"
"Test case prioritization techniques for software product line: A survey","S. Kumar; Rajkumar","Department of Computer Science, Gurukula Kangri Vishwavidyalaya, Haridwar, India; Gurukula Kangri vishwavidyalaya, Hardwar, Uttarakhand, IN","2016 International Conference on Computing, Communication and Automation (ICCCA)","16 Jan 2017","2016","","","884","889","Software product line (SPL) testing is a tougher work than testing of single systems. Still testing of each individual SPL product would be perfect but it is too costly in practice. In fact, when the number of features increases then the number of possible products also increases exponentially usually derived from a feature model. Number of features is leading to thousands of different products. Due to cost and time constraints, it is infeasible or large number of effort to run all the test cases in an existing test suite. To decrease the cost of testing, various techniques have been proposed. One of them is test case prioritization (TCP) techniques. Here we presented a survey for TCP techniques for software SPL.","","978-1-5090-1666-2","10.1109/CCAA.2016.7813841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813841","Software product lines;Test Case Prioritization;Variability;Commonality;Feature Model","Software;Software product lines;Testing;Frequency modulation;Fault detection;Automation;Libraries","program testing;software product lines","software product line;SPL product;feature model;test suite;test case prioritization;TCP","","8","","30","IEEE","16 Jan 2017","","","IEEE","IEEE Conferences"
"Test Set Diameter: Quantifying the Diversity of Sets of Test Cases","R. Feldt; S. Poulding; D. Clark; S. Yoo","Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Computer Science, University College London, London, UK; School of Computing KAIST, Daejeon, Republic of Korea","2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)","21 Jul 2016","2016","","","223","233","A common and natural intuition among software testers is that test cases need to differ if a software system is to be tested properly and its quality ensured. Consequently, much research has gone into formulating distance measures for how test cases, their inputs and/or their outputs differ. However, common to these proposals is that they are data type specific and/or calculate the diversity only between pairs of test inputs, traces or outputs. We propose a new metric to measure the diversity of sets of tests: the test set diameter (TSDm). It extends our earlier, pairwise test diversity metrics based on recent advances in information theory regarding the calculation of the normalized compression distance (NCD) for multisets. A key advantage is that TSDm is a universal measure of diversity and so can be applied to any test set regardless of data type of the test inputs (and, moreover, to other test-related data such as execution traces). But this universality comes at the cost of greater computational effort compared to competing approaches. Our experiments on four different systems show that the test set diameter can help select test sets with higher structural and fault coverage than random selection even when only applied to test inputs. This can enable early test design and selection, prior to even having a software system to test, and complement other types of test automation and analysis. We argue that this quantification of test set diversity creates a number of opportunities to better understand software quality and provides practical ways to increase it.","","978-1-5090-1827-7","10.1109/ICST.2016.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515474","Software testing;Information theory;Test selection;Empirical study","Measurement;Complexity theory;Software testing;Electronic mail;Software systems","program testing;software fault tolerance;software metrics;software quality","software quality;test set diversity;fault coverage;NCD;normalized compression distance;pairwise test diversity metrics;TSDm;software system;software testers;test cases;test set diameter","","53","","41","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"A Test Suit Reduction Method Based on Defect Detecting Capabilit","Z. Sun; T. Zhang; Y. Peng; L. Wu; Y. Yan; Y. Zhang","Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China; Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China; Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China; Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China; Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China; Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China","2019 IEEE 2nd International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)","12 Mar 2020","2019","","","45","48","The scale of test cases and the ability to detect defects determine the cost and effectiveness of software testing. A well-designed test suit reduction method should maximize the effectiveness of defect detection while reducing the cost of software testing. In this paper, a test suit reduction method based on defect detection capability is presented. The scale of the test cases to be selected and their defect detection capability are fully considered in the reduction process. The example application shows that compared with the traditional single-objective heuristic algorithm, the test case reduction set obtained by this method has improved in scale and defect detection ability.","","978-1-7281-5030-7","10.1109/AUTEEE48671.2019.9033228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9033228","software testing;test suit reduction;defect detection capability","Heuristic algorithms;Software;Linear programming;Fault detection;Approximation algorithms;Software testing","program testing","software testing;defect detection capability;reduction process;test case reduction;defect detection ability;test suit reduction method","","1","","13","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Towards Reduction of Software Maintenance Cost through Assignment of Critical Functionality Scores","L. S. Nair; J. Swaminathan","Department of Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Amritapuri Campus, India; Department of Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Amritapuri Campus, India","2020 5th International Conference on Communication and Electronics Systems (ICCES)","10 Jul 2020","2020","","","199","204","Software maintenance incurs a significant cost during the life cycle of any software product. This is due to multiple factors such as addition of features demanded by new requirements, modification of existing features triggered by fixing of defects in the code and extending product support to newer platforms. These factors cause the testing phase to be repeated each time thereby increasing the maintenance cost. The quality of the code compounds to the maintenance cost since poorly written code are hard to comprehend and work with. This paper proposes a methodology to reduce the testing effort through successive releases by determining a set of most significant functionalities by computing scores based on the usage frequency, code maintainability and change vulnerability. The scores are recomputed as the software evolves over successive releases to keep the testing effort minimal.","","978-1-7281-5371-1","10.1109/ICCES48766.2020.9138071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138071","Static Code Analysis;Scala;Call graph;unit testing;integration testing;Maintainability Index","Software maintenance;Codes;Costs;Maintenance engineering;Indexes;Compounds;Testing","program testing;software cost estimation;software maintenance","code maintainability;change vulnerability;software maintenance cost reduction;critical functionality scores;software product life cycle;testing phase;code compounds","","","","16","IEEE","10 Jul 2020","","","IEEE","IEEE Conferences"
"DevOps Improvements for Reduced Cycle Times with Integrated Test Optimizations for Continuous Integration","D. Marijan; M. Liaaen; S. Sen","Simula, Norway; Cisco Systems, Norway; Simula, Norway","2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)","22 Jun 2018","2018","01","","22","27","DevOps, as a growing development practice that aims to enable faster development and efficient deployment of applications without compromising on quality, is often hampered by long cycle times. One contributing factor to long cycle times in DevOps is long build time. Automated testing in continuous integration is one of the build stages that is highly prone to long run-time due to software complexity and evolution, and inefficient due to unoptimized testing approaches. To be cost-effective, testing in continuous integration needs to use only a fast-running set of comprehensive tests that are able to ensure the level of quality needed for deployment to production. Known approaches use time-aware test selection methods to improve time-efficiency of continuous integration testing by providing optimized combinations and order of tests with respect to decreased run-time. However, focusing on time-efficiency as the sole criterion in DevOps often jeopardizes the quality of software deliveries. This paper proposes a technique that integrates fault-based and risk-based test selection and prioritization optimized for low run-time, to improve time-effectiveness of continuous integration testing, and thus reduce long cycle times in DevOps, without compromising on quality. The technique has been evaluated in testing of a large-scale configurable software in continuous integration, and has shown considerable improvement over industry practice with respect to time-efficiency.","0730-3157","978-1-5386-2667-2","10.1109/COMPSAC.2018.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377636","DevOps, Continuous integration testing, Test prioritization, History-based test prioritization, Risk-based test optimization, Fault-based test prioritization","Testing;Software;Optimization;Production;Fault detection;Industries;Indexes","program testing","unoptimized testing approaches;comprehensive tests;time-aware test selection methods;continuous integration testing;risk-based test selection;time-effectiveness;DevOps improvements;integrated test optimizations;automated testing","","8","","20","IEEE","22 Jun 2018","","","IEEE","IEEE Conferences"
"[Journal First] A Correlation Study Between Automated Program Repair and Test-Suite Metrics","J. Yi; S. H. Tan; S. Mechtaev; M. Böhme; A. Roychoudhury",NA; NA; NA; NA; NA,"2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","2 Sep 2018","2018","","","24","24","Automated program repair has attracted attention due to its potential to reduce debugging cost. Prior works show the feasibility of automated repair, and the research focus is gradually shifting towards the quality of generated patches. One promising direction is to control the quality of generated patches by controlling the quality of test-suites used. In this paper, we investigate the question: """"Can traditional test-suite metrics used in software testing be used for automated program repair?"""". We empirically investigate the effectiveness of test-suite metrics (statement / branch coverage and mutation score) in controlling the reliability of repairs (the likelihood that repairs cause regressions). We conduct the largest-scale experiments to date with real-world software, and perform the first correlation study between test-suite metrics and the reliability of generated repairs. Our results show that by increasing test-suite metrics, the reliability of repairs tend to increase. Particularly, such trend is most strongly observed in statement coverage. This implies that traditional test-suite metrics used in software testing can also be used to improve the reliability of repairs in program repair.","1558-1225","978-1-4503-5638-1","10.1145/3180155.3182517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453057","Code Coverage;Program Repair;Mutation Testing","Maintenance engineering;Measurement;Correlation;Software reliability;Software;Software testing","program debugging;program testing;software maintenance","regressions;test-suite metrics;automated repair;generated repairs;correlation study;automated program repair;software testing;test-suites;generated patches","","2","","","","2 Sep 2018","","","IEEE","IEEE Conferences"
"Application of Mahalanobis-Taguchi Method and 0-1 Programming Method to Cost-Effective Regression Testing","H. Aman; Y. Tanaka; T. Nakano; H. Ogasawara; M. Kawahara","Center for Information Technology, Ehime University, Matsuyama, Japan; Toshiba Corporation, Kawasaki, Japan; Toshiba Corporation, Kawasaki, Japan; Toshiba Corporation, Kawasaki, Japan; Center for Information Technology, Ehime University, Matsuyama, Japan","2016 42th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","18 Oct 2016","2016","","","240","244","To enhance the cost effectiveness of regression testing, this paper proposes a method for prioritizing test cases. In general, a test case can be evaluated from various different points of view, therefore whether it is worth it to re-run should be discussed using multi criteria. This paper shows that the Mahalanobis-Taguchi (MT) method is a useful way to successfully integrate different evaluations of a test case. Moreover, this paper proposes to use the 0-1 programming method together with the MT method in order to take into account not only the priority of a test case but also its cost to run. The empirical study with 300 test cases for an industrial software system shows that the combination of the MT method and the 0-1 programming method is more cost-effective than other conventional methods.","2376-9505","978-1-5090-2820-7","10.1109/SEAA.2016.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592803","Mahalanobis-Taguchi method;0-1 programming method;regression testing","Testing;Programming;Measurement;Computer aided software engineering;Software;Focusing;History","mathematical programming;program testing;regression analysis","Mahalanobis-Taguchi method;0-1 programming method;cost-effective regression testing;test case prioritization;MT method","","5","","12","IEEE","18 Oct 2016","","","IEEE","IEEE Conferences"
"How Do Static and Dynamic Test Case Prioritization Techniques Perform on Modern Software Systems? An Extensive Study on GitHub Projects","Q. Luo; K. Moran; L. Zhang; D. Poshyvanyk","Department of Computer Science, College of William and Mary, Williamsburg; Department of Computer Science, College of William and Mary, Williamsburg; Department of Computer Science, University of Texas at Dallas, Dallas; Department of Computer Science, College of William and Mary, Williamsburg","IEEE Transactions on Software Engineering","12 Nov 2019","2019","45","11","1054","1080","Test Case Prioritization (TCP) is an increasingly important regression testing technique for reordering test cases according to a pre-defined goal, particularly as agile practices gain adoption. To better understand these techniques, we perform the first extensive study aimed at empirically evaluating four static TCP techniques, comparing them with state-of-research dynamic TCP techniques across several quality metrics. This study was performed on 58 real-word Java programs encompassing 714 KLoC and results in several notable observations. First, our results across two effectiveness metrics (the Average Percentage of Faults Detected APFD and the cost cognizant APFDc) illustrate that at test-class granularity, these metrics tend to correlate, but this correlation does not hold at test-method granularity. Second, our analysis shows that static techniques can be surprisingly effective, particularly when measured by APFDc. Third, we found that TCP techniques tend to perform better on larger programs, but that program size does not affect comparative performance measures between techniques. Fourth, software evolution does not significantly impact comparative performance results between TCP techniques. Fifth, neither the number nor type of mutants utilized dramatically impact measures of TCP effectiveness under typical experimental settings. Finally, our similarity analysis illustrates that highly prioritized test cases tend to uncover dissimilar faults.","1939-3520","","10.1109/TSE.2018.2822270","NSF(grant numbers:CCF-1218129,CCF-1566589); NSF(grant numbers:CNS-1510239); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329518","Regression testing;test case prioritization;static;dynamic;mutation analysis","Testing;Measurement;Computer bugs;Software systems;Java;Fault detection","fault diagnosis;Java;program testing;regression analysis","regression testing technique;static TCP techniques;dynamic TCP techniques;quality metrics;real-word Java programs;test-class granularity;test-method granularity;static techniques;TCP effectiveness;static test case prioritization techniques;dynamic test case prioritization techniques;software systems;GitHub projects","","34","","76","IEEE","2 Apr 2018","","","IEEE","IEEE Journals"
"A survey on the practices of mobile application testing","I. Santos; J. C. C. Filho; S. R. S. Souza","Institute of Mathematics and Computer Science (ICMC), University of São Paulo (USP), São Carlos, Brazil; Institute of Mathematics and Computer Science (ICMC), University of São Paulo (USP), São Carlos, Brazil; Institute of Mathematics and Computer Science (ICMC), University of São Paulo (USP), São Carlos, Brazil","2020 XLVI Latin American Computing Conference (CLEI)","28 Jun 2021","2020","","","232","241","Context: Mobile devices have become increasingly popular, and mobile applications should guarantee a very high level of reliability and quality. Mobile application testing needs to consider several unique requirements that distinguish it from conventional software testing. Objective: Our study aims to establish an overview of the testing practices conducted in mobile companies, to identify weaknesses that can be improved to make the testing activity more effective. Method: The survey questions were carefully designed using the Goal/Question/Metric method to provide relevant information to the questions raised in our study. Results and Conclusions: Our study outlines that native applications are more common. The testing level more performed is the system test and the positions that perform testing levels and objectives are described. Practices related to testing technique selection in the context of mobile applications are highlighted. In the context of this study, Cucumber and Selenium are the testing tools most used to automate testing activity. Some mobile testing characteristics were outlined to understand how the testing in mobile applications run on different devices, how testers deal with the diversity of operating systems that are constantly updated and whether tests are unified to testing a mobile app that runs in different platforms. Furthermore, we report the main challenges faced by testers during the validation of the mobile app.","","978-1-6654-1560-6","10.1109/CLEI52000.2020.00034","FAPESP (Sao Paulo Research Foundation)(grant numbers:2018/10183-9,2019/06937-0); CNPq(grant numbers:312922/2018-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458347","Survey;Mobile testing;Software testing practices;Software quality","Software testing;Operating systems;Companies;Tools;Mobile handsets;Mobile applications;Software reliability","mobile computing;program testing;software metrics","mobile application testing;mobile devices;mobile applications;testing practices;mobile companies;testing level;system test;testing levels;testing technique selection;testing tools;automate testing activity;mobile testing characteristics;mobile app","","4","","21","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Research on CPN Model Reduction Focus on Parallel Tested Behaviors","T. Sun; W. Zhang; X. Guo; X. Wan","Inner Mongolia University, Hohhot, Inner Mongolia, CN; Inner Mongolia University, Hohhot, Inner Mongolia, CN; Inner Mongolia University, Hohhot, Inner Mongolia, CN; Inner Mongolia University, Hohhot, Inner Mongolia, CN","2017 IEEE International Symposium on Parallel and Distributed Processing with Applications and 2017 IEEE International Conference on Ubiquitous Computing and Communications (ISPA/IUCC)","28 May 2018","2017","","","827","833","Nowadays parallel software system is very common and practical. However, it is difficult to test parallel software, because the state space of parallel software is very large. Therefore, a parallel model simplification method based on CPN (Color Petri Net) is proposed. Based on the original CPN, the CPN model for the tested behavior(Tested Behavior of CPN, TBoCPN) is proposed. The target of the test is described as the tested behavior. The relevant behavior is described as the behavior related to the tested behavior, then, the homogeneous concurrent branch group and the selection branch set are divided. Finally, the branches of the concurrent branch group and the selected branch set, which satisfied the condition of algorithm, are sequentially processed by the inhibitor arcs. The experiment shows that the reduction rate is at least 60%, and before and after the reduction, the full coverage test path generated by the tested behavior is not affected, thus proving that the method is an effective test method.","","978-1-5386-3790-6","10.1109/ISPA/IUCC.2017.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367356","parallel software;CPN;tested behavior;related--behavior;concurrent branch group;selection branch set;full-coverage","Unified modeling language;Computational modeling;Software systems;Inhibitors;Electronic mail","concurrency (computers);parallel processing;Petri nets;program testing","test parallel software;parallel model simplification method;homogeneous concurrent branch group;selected branch set;coverage test path;parallel software system;CPN model reduction;parallel tested behaviors;branch set selection;color Petri net;TBoCPN","","1","","13","IEEE","28 May 2018","","","IEEE","IEEE Conferences"
"Scalable Mutation Testing Using Predictive Analysis of Deep Learning Model","M. R. Naeem; T. Lin; H. Naeem; F. Ullah; S. Saeed","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Computer Information Systems, College of Computer Science and Information Technology, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia","IEEE Access","7 Nov 2019","2019","7","","158264","158283","Software testing plays a crucial role in ensuring the quality of software systems. Mutation testing is designed to measure the adequacy of test suites by detecting artificially induced software faults. Despite their potential, the expensive cost and the scalability of mutation testing with large programs is a big obstacle in its practical use. The selective mutation has been widely investigated and considered to be an effective approach to reduce the cost of mutation testing. In the case of large programs where source code has hundreds of classes and more than 10 KLOC lines of code, the selective mutation can still generate thousands of mutants. Executing each mutant against the test suite is cost-intensive in terms of robustness, resource usage, and computational cost. In this paper, we introduce a new approach to extract features from mutant programs based on mutant killing conditions, i.e. reachability, necessity and sufficiency along with mutant significance and test suite metrics to extract features from mutant programs. A deep learning Keras model is proposed to predict killed and alive mutants from each program. First, the features are extracted using the Eclipse JDT library and program dependency analysis. Second, preprocessing techniques such as Principal Component Analysis and Synthetic Minority Oversampling are used to reduce the high dimensionality of data and to overcome the imbalanced class problem respectively. Lastly, the deep learning model is optimized using fine-tune parameters such as dropout and dense layers, activation function, error and loss rate respectively. The proposed work is analyzed on five opensource programs from GitHub repository consisting of thousands of classes and LOC. The experimental results are appreciable in terms of effectiveness and scalable mutation testing with a slight loss of accuracy.","2169-3536","","10.1109/ACCESS.2019.2950171","Science and Technology Planning Program of Sichuan University and Luzhou(grant numbers:2017CDLZG30); Sichuan University(grant numbers:2019SCU12058); 2018–2020 Higher Education Talent Training Quality and Teaching Reform Project of Sichuan Province(grant numbers:JG2018-46); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886413","Scalable mutation testing;static analysis;deep learning;binary classification","Feature extraction;Benchmark testing;Deep learning;Scalability;Predictive models;Software","feature extraction;learning (artificial intelligence);principal component analysis;program diagnostics;program testing;public domain software;software fault tolerance;software quality;source code (software)","open source programs;GitHub repository;test suite metrics;fine-tune parameters;data dimensionality reduction;imbalanced class problem;synthetic minority oversampling;principal component analysis;preprocessing techniques;program dependency analysis;Eclipse JDT library;feature extraction;computational cost;source code;cost reduction;artificially induced software fault detection;software quality;predictive analysis;mutant killing conditions;selective mutation;software systems;software testing;scalable mutation testing;deep learning model;deep learning Keras model;mutant programs;test suite","","6","","45","CCBY","30 Oct 2019","","","IEEE","IEEE Journals"
"A Test Case Prioritization Approach Based on Software Component Metrics","D. S. Silva; R. Rabelo; P. S. Neto; R. Britto; P. A. Oliveira","Computer Science Department, Federal University of Piauí, Teresina, Piauí, Brazil; Computer Science Department, Federal University of Piauí, Teresina, Piauí, Brazil; Computer Science Department, Federal University of Piauí, Teresina, Piauí, Brazil; Blekinge Institute of Technology, Karlskrona, Sweden; Federal Institute of Maranhao, Pedreiras, Maranhao, Brazil","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","2939","2945","The most common way of performing regression testing is by executing all test cases associated with a software system. However, this approach is not scalable since time and cost to execute the test cases increase together with the system’s size. A way to address this consists of prioritizing the existing test cases, aiming to maximize a test suite’s fault detection rate. To address the limitations of existing approaches, in this paper we propose a new approach to maximize the rate of fault detection of test suites. Our proposal has three steps: i) infer code components’ criticality values using a fuzzy inference system; ii) calculate test cases’ criticality; iii) prioritize the test cases using ant colony optimization. The test cases are prioritized considering criticality, execution time and history of faults, and the resulting test suites are evaluated according to their fault detection rate. The evaluation was performed in eight programs, and the results show that the fault detection rate of the solutions was higher than in the non-ordered test suites and ones obtained using a greedy approach, reaching the optimal value when possible to verify. A sanity check was performed, comparing the obtained results to the results of a random search. The approach performed better at significant levels of statistic and practical difference, evidencing its true applicability to the prioritization of test cases.","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8914670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914670","","Fault detection;Testing;Software;Fuzzy logic;Measurement;History;Fuzzy sets","fault diagnosis;fuzzy reasoning;optimisation;program testing;regression analysis;software metrics","resulting test suites;fault detection rate;nonordered test suites;test case prioritization approach;regression testing;software component metrics;fuzzy inference system;sanity check","","1","","20","IEEE","28 Nov 2019","","","IEEE","IEEE Conferences"
"Combining Code and Requirements Coverage with Execution Cost for Test Suite Reduction","A. Marchetto; G. Scanniello; A. Susi","NA; DiMIE, University of Basilicata, Potenza, Italy; Fondazione Bruno Kessler, Trento, Italy","IEEE Transactions on Software Engineering","16 Apr 2019","2019","45","4","363","390","Test suites tend to become large and complex after software evolution iterations, thus increasing effort and cost to execute regression testing. In this context, test suite reduction approaches could be applied to identify subsets of original test suites that preserve the capability of satisfying testing requirements and revealing faults. In this paper, we propose Multi-Objective test suites REduction (named MORE+): a three-dimension approach for test suite reduction. The first dimension is the structural one and concerns the information on how test cases in a suite exercise the under-test application. The second dimension is functional and concerns how test cases exercise business application requirements. The third dimension is the cost and concerns the time to execute test cases. We define MORE+ as a multi-objective approach that reduces test suites so maximizing their capability in revealing faults according to the three considered dimensions. We have compared MORE+ with seven baseline approaches on 20 Java applications. Results showed, in particular, the effectiveness of MORE+ in reducing test suites with respect to these baselines, i.e., significantly more faults are revealed with test suites reduced by applying MORE+.","1939-3520","","10.1109/TSE.2017.2777831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120000","Multi-objective approach;regression testing;testing;test suite reduction","Testing;Software;Business;Java;Space exploration;Large scale integration;Software engineering","Java;program testing;regression analysis;software fault tolerance;software maintenance","test cases;suite exercise;under-test application;regression testing;original test suites;MultiObjective test suites REduction","","13","","79","IEEE","27 Nov 2017","","","IEEE","IEEE Journals"
"A Prioritization Method for SPL Pairwise Testing Based on User Profiles","H. Akimoto; Y. Isogami; T. Kitamura; N. Noda; T. Kishi","Department of Industrial and Management Systems Engineering, Waseda University, Tokyo, Japan; Department of Industrial and Management Systems Engineering, Waseda University, Tokyo, Japan; Kansai Center, National Institute of Advanced Industrial Science and Technology, Osaka, Japan; College of Engineering and Design, Shibaura Institute of Technology, Tokyo, Japan; Department of Industrial and Management Systems Engineering, Waseda University, Tokyo, Japan","2019 26th Asia-Pacific Software Engineering Conference (APSEC)","2 Jan 2020","2019","","","118","125","In Software Product Line (SPL) development, one of promising techniques for core asset testing is to test a subset of SPL as representative products. SPL pairwise testing is a such technique in which each product corresponds to a possible feature configuration in the feature model (FM) and representative products are selected so as to all possible feature pairs are included. It is also important to prioritize representative products, because it could improve the effectiveness of core asset testing especially when the testing resource is limited. In this paper, we propose a prioritization method for SPL pairwise testing based on user profiles. A user profile is a set of user groups and their occurrence probabilities such as the percentages of user groups in a market that use specific devices, applications or services. These profiles are used as the probabilities of feature choices at decision points such as optional features and alternative features in a FM. Based on that, we calculate the probability for obtaining a feature pairs (PFP for short), and generate representative products with priority. Most researches relate to the probabilities about FM handle the probability for obtaining a single feature (PSF for short). Based on PSF, we could estimate PFP. However, this estimation is not appropriate for the prioritization especially when conditional probabilities appear in user profiles. In our method, we directly calculate PFP and determine the priorities. We evaluate the method to show advantages of prioritizations using PFP over those using PSF, and also analyze the characteristics of the method.","2640-0715","978-1-7281-4648-5","10.1109/APSEC48747.2019.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945722","software product lines, pairwise testing, user profiles, test case prioritization","Testing;Frequency modulation;Face;Probability;Fingers;Cameras;Modeling","probability;program testing;software product lines","core asset testing;prioritization method;SPL pairwise testing;software product line development;feature configuration;feature model;user profiles","","5","","33","IEEE","2 Jan 2020","","","IEEE","IEEE Conferences"
"Software Testing in Industry and Academia: A View of Both Sides in Japan","S. Masuda","IBM Research Tokyo Chuou-ku, Tokyo, Japan","2017 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","17 Apr 2017","2017","","","40","41","Collaboration between industry and academia is important for solving problems and creating innovations. Both sides of industry and academia are important for each other, but sometimes they are incompatible. In this paper, we discuss software testing in industry and academia from their respective views in Japan on the basis of the author's experiences and studies. High quality software is required and its industry is influenced by economic circumstances. In Japan, there are also problems regarding cost reductions, production of high quality software, adapting businesses, and so on. We have made efforts to solve these problems by collaborating with people in both industry and academia. Our efforts include developing test methodologies, skill standards, education syllabi, and so on.","","978-1-5090-6676-6","10.1109/ICSTW.2017.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899029","Software Testing;Software Testing Industry;Industry Academia Collaboration","Industries;Software testing;Software;Education;Information technology;Economics","program testing;software quality","software testing;Japan;software quality;cost reduction;industry-academia collaboration","","3","","15","IEEE","17 Apr 2017","","","IEEE","IEEE Conferences"
"Optimization of automated executions based on integration test configurations of embedded software","M. Mizoguchi; T. Iida; T. Irie","Hitachi, Ltd., Hitachi City, Ibaraki Pref., Japan; Hitachi Automotive Systems, Ltd., HitachinakaCity, Ibaraki Pref., Japan; Hitachi Automotive Systems, Ltd., HitachinakaCity, Ibaraki Pref., Japan","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","358","363","For embedded systems, software has become more and more important. The scale of software has increased, and cost for software testing has also increased. Especially, integration tests should be made more efficient because they usually occupy most of testing cost. As well as web and office applications, automated executions with formal test scripts are effective for embedded systems. However, in case of embedded systems, it is necessary to reconfigure test environments by adjusting settings of a microcomputer and a simulator of external environments to test scripts. Then, it is important to reduce the cost of reconfigurations in terms of the efficiency of integration tests. In this paper, we propose a method to optimize the order of executions of test scripts and minimize the number of times of reconfigurations. We found that the differences of configurations comes from hardware requirements on the embedded systems. We introduce a feature tree to describe the hardware requirements and associate them to each test script. Based on given hardware requirements, test scripts that are executable on the same configuration are executed consecutively. The proposed method is evaluated with a part of integration tests for automotive software. We have the prospect that the number of reconfiguration is reduced from 328 to 187 to test 53,483 test scripts.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155726","embedded software;integration test;automation;configuration","Embedded systems;Automotive engineering;Hardware;Microcomputers;Embedded software;Testing","automotive engineering;embedded systems;program testing","embedded software;embedded systems;software testing;integration tests;testing cost;automated executions;formal test scripts;test environments;integration test configurations;automotive software;microcomputer;hardware requirements","","","","44","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"ACT Testbot and 4S Quality Metrics in XAAS Framework","D. Chhillar; K. Sharma","Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India; Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India","2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)","11 Oct 2019","2019","","","503","509","The purpose of this paper is to analyze all Cloud based Service Models, Continuous Integration, Deployment and Delivery process and propose an Automated Continuous Testing and testing as a service based TestBot and metrics dashboard which will be integrated with all existing automation, bug logging, build management, configuration and test management tools. Recently cloud is being used by organizations to save time, money and efforts required to setup and maintain infrastructure and platform. Continuous Integration and Delivery is in practice nowadays within Agile methodology to give capability of multiple software releases on daily basis and ensuring all the development, test and Production environments could be synched up quickly. In such an agile environment there is need to ramp up testing tools and processes so that overall regression testing including functional, performance and security testing could be done along with build deployments at real time. To support this phenomenon, we researched on Continuous Testing and worked with industry professionals who are involved in architecting, developing and testing the software products. A lot of research has been done towards automating software testing so that testing of software product could be done quickly and overall testing process could be optimized. As part of this paper we have proposed ACT TestBot tool, metrics dashboard and coined 4S quality metrics term to quantify quality of the software product. ACT testbot and metrics dashboard will be integrated with Continuous Integration tools, Bug reporting tools, test management tools and Data Analytics tools to trigger automation scripts, continuously analyze application logs, open defects automatically and generate metrics reports. Defect pattern report will be created to support root cause analysis and to take preventive action.","","978-1-7281-0211-5","10.1109/COMITCon.2019.8862212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862212","Cloud;ACT (Automated Continuous Testing);TestBot;Continuous Testing;Continuous Integration;Continuous Delivery;Continuous Deployment;XaaS (Everything as a Service);T-Model;Auto Bug Logging and Tracking;4S Quality Metrics","Testing;Tools;Cloud computing;Security;Computer bugs;Software as a service","automatic testing;cloud computing;data analysis;program debugging;program testing;security of data;software metrics;software prototyping;software quality","automation scripts;metrics reports;XAAS framework;metrics dashboard;bug logging;test management tools;agile environment;testing tools;regression testing;security testing;software product;testing process;ACT TestBot tool;data analytics tools;service models;agile methodology;software testing;continuous integration tools;automated continuous testing;bug reporting tools;4S quality metrics;cloud based service models;testing as a service","","","","18","IEEE","11 Oct 2019","","","IEEE","IEEE Conferences"
"System Integration Testing for Unintended Behaviors in Flight-Critical Aerospace Applications","J. Winter","Integrated Air Data Systems, Collins Aerospace, Burnsville, USA","2020 IEEE International Systems Conference (SysCon)","7 Dec 2020","2020","","","1","5","From the systems development planning phase all the way through aircraft-level implementation verification, a focus on monitoring for and detecting unintended behaviors (instead of solely trying to prevent them) can increase aircraft safety and improve product robustness. Through the lens of designing and verifying a modern Air Data System, a flight critical product, this case study delves into numerous Systems Engineering practices focused on identifying and addressing unintended behavior early in the product development lifecycle. The paper's focus will be highlighting methods for meeting the unintended behavior related objectives of SAE ARP4754A for an example system's Design Assurance Level A items/functions and will include an accepted framework for System Stages of Involvement (SOI) audit success. Specific, real world cases where engineering actions have prevented unintended behavior during Commercial, Regional, or Business Jet service will be highlighted and compared with the types of unintended behavior investigated during hardware/software integration and implementation verification. Additionally, the paper will provide evidence related to this topic which supports the common industry perception that issues found and fixed earlier in the development period incur less cost. Finally, the paper will include a discussion of fertile grounds for discovering unintended behavior considering a standard/common specification level.","2472-9647","978-1-7281-5365-0","10.1109/SysCon47679.2020.9275658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275658","Aerospace systems;case study;integration testing;SAE ARP4754;systems engineering;unintended behavior","Testing;Aircraft;Data systems;Aircraft propulsion;Software;Heating systems;System integration","aerospace computing;aerospace safety;aircraft;auditing;avionics;cost reduction;design engineering;embedded systems;formal verification;product development;program testing;software engineering;systems engineering","System integration testing;flight-critical aerospace applications;systems development planning phase;aircraft-level implementation verification;flight critical product;systems engineering practices;unintended behavior related objectives;modern air data system;system stages of involvement","","","","2","IEEE","7 Dec 2020","","","IEEE","IEEE Conferences"
"Trace-Based Test Selection to Support Continuous Integration in the Automotive Industry","S. Vöst; S. Wagner","BMW Group University of Stuttgart, Germany; Universitat Stuttgart, Stuttgart, Baden-WÃ¼rttemberg, DE","2016 IEEE/ACM International Workshop on Continuous Software Evolution and Delivery (CSED)","9 Jan 2017","2016","","","34","40","System testing in the automotive industry is a very expensive and time-consuming task of growing importance, because embedded systems in the domain are distributed over numerous controllers (ECUs). Modern software development techniques such as continuous integration require regular, repeated and fast testing. To achieve this in the automotive domain, test suites for a specific software change must be tailored.We propose a novel test selection technique for system-level functions in the automotive industry based on component and communication models. The idea is to follow input and output signals that are used in the testing steps through the ECUs implementing a function. We select only those tests for a planned integration in which at least one of the signals sent in its steps is processed by the ECU that was changed and thus triggered the integration. The technique is well-suited for black-box testing since it requires only the full test suite specification and the system architecture.We applied the technique to a test suite of the Active Cruise Control function at BMW Group in the context of hardware-in-the-loop system testing and found the possible reduction rates to be 82.3% on average in comparison to the full test suite.Possible future work includes the evaluation with a wider set of functions, the evaluation of the fault detection rate, further automation and combination with other test selection techniques.","","978-1-4503-4157-8","10.1145/2896941.2896951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809433","Test Case Selection;Continuous Integration;Embedded Systems;System Testing","Automotive engineering;Industries;System testing;Vehicles;Embedded systems","automobile industry;embedded systems;production engineering computing;production testing;program testing;software engineering","trace-based test selection;continuous integration support;automotive industry;system testing;embedded systems;software development techniques;software change;test selection technique;Active Cruise Control function;BMW Group;hardware-in-the-loop system testing","","1","","15","","9 Jan 2017","","","IEEE","IEEE Conferences"
"Regression Test Suite Reduction for Cloud Systems","O. Jebbar; M. A. Saied; F. Khendek; M. Toeroe","Gina Cody School of Engineering and Computer Science, Concordia University, Montreal, Canada; Computer Science and Software Engineering, Laval University, Quebec, Canada; Gina Cody School of Engineering and Computer Science, Concordia University, Montreal, Canada; Ericsson Canada Inc., Montreal, Canada","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","477","486","Cloud providers offer a wide variety of services to their tenants. Providers share large scale infrastructures to host their services and use configurable software customized with configurations to meet different tenant requirements. These configurations are often the main source of errors. Moreover, they undergo frequent changes, therefore, systems' compliance to requirements needs to be re-evaluated frequently using regression testing. The problem of regression test case selection has been extensively addressed in the literature, however, existing approaches do not tackle the problem from the configuration perspective. In this paper, we propose a configuration-based method for regression test suite reduction for cloud systems. Our method targets a set of faults summarized in a fault model, and it relies on a classification of configuration parameters based on their relation to the deployment environment. Our idea is that the relation of the configuration parameters to the environment can be explored to reduce the regression test suite.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155903","cloud systems;configurable systems;configurations;regression testing;test suite reduction","Software;Testing;Computer architecture;Credit cards;Computer science;Production;Conferences","cloud computing;program testing;regression analysis","regression test suite reduction;cloud systems;cloud providers;configurable software;different tenant requirements;regression testing;regression test case selection;configuration perspective;configuration-based method;configuration parameters","","","","19","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Minimizing the size of test suite using genetic algorithm for object oriented program","S. Kothari; A. Rajavat","Computer Science Department, Shri Vaishnav Institute of Technology & Science, Indore, M.P., India; Computer Science Department, Shri Vaishnav Institute of Technology & Science, Indore, M.P., India","2016 International Conference on ICT in Business Industry & Government (ICTBIG)","6 Apr 2017","2016","","","1","5","Software development and management of large scale projects are the complicated task. To support the software developers, the object oriented methodologies are used for reducing development efforts. But still a significant amount of efforts and team work is required to design and develop the systems according to the users need. Among them the testing is a one of the key components of software development life cycle. The testing assures about the quality of software development and their services. In this presented work, a new software testing model is proposed and implemented that offers the automated testing with test case generation, optimization and code evaluation. The implementation of the future method is provided using the JAVA based technologies and their performance is also computed with number of different experiments. During experimentations, either the LOC (line of code) increases to measure the stability of performance or optimization steps increase to find the efficiency of the proposed model. The experimental results demonstrate that the future method is capable to analyse small as well as large scale projects with the less resource consumption and more accurately.","","978-1-5090-5515-9","10.1109/ICTBIG.2016.7892703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892703","Software engineering;SDLC;testing;test set optimization;implementation;performance assessment","Optimization;Testing;Sociology;Statistics;Software;Genetic algorithms;Memory management","genetic algorithms;Java;object-oriented programming;program testing","test suite;genetic algorithm;object oriented program;software management;object oriented methodologies;team work;system design;system development;software development life cycle;software testing;automated testing;test case generation;optimization;code evaluation;JAVA based technologies;LOC;line of code","","3","","11","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Design and development of an automated RF test platform for low noise Pre-Amp","T. Thomas; A. Thomas; V. M. Sreekumar","Department of Electronics and Communication Engineering, Rajagiri School of Engineering and Technology, Kochi, India; Department of Electronics and Communication Engineering, Rajagiri School of Engineering and Technology, Kochi, India; Department of Test Engineering, SFO Technologies Digital Pvt LTD NeST Group, Kochi, India","2017 International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)","13 Jul 2017","2017","","","177","180","The testing process of a low noise RF pre-amp in most of the semiconductor fabrication industries is either fully manual or employs expensive test systems. An efficient and low cost automated testing system is elucidated in this paper. The design and development of the automated RF test system is realized. The whole process involves the development of an Automated Test System (ATE) and a software test application to control the tests. The test system uses a RF network analyzer, to automatically measure s-parameter values at 63.86 MHz and 127.72 MHz, depending upon the operating frequency of the pre-amplifier. The system primarily focuses on automating the standard vector network analyzer. The costs involved in the production of a large volume of preamps used in 1.5T and 3T MRI machines is minimized using this automated RF testing methodology. In addition, test operator intervention is significantly reduced. The automated test system minimizes programming and firmware complexities in the test operator level and finally, generates a simple Pass/Fail status and impart the measured s-parameter data to the operator. A detailed analysis is performed to correlate the obtained result to the traditional test setup where in the devised testing method is found to be more accurate and reliable. Also, the impact of the proposed test setup on the final cost per unit is verified.","","978-1-5090-5960-7","10.1109/ICIMIA.2017.7975596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975596","Automated RF testing system;Vector Network Analyzer;Automated Test Equipment;Custom test fixture","Radio frequency;Fixtures;Testing;Instruments;Correlation;Software","automatic test equipment;low noise amplifiers;magnetic resonance imaging;network analysers;preamplifiers;program testing;S-parameters;VHF amplifiers","automated RF test platform;low noise RF pre-amp;semiconductor fabrication industr;automated test system;ATE;software test application;RF network analyzer;S-parameter;pre-amplifier;vector network analyzer;MRI machines;programming complexity;firmware complexity;simple pass-fail status;frequency 63.86 MHz;frequency 127.72 MHz","","","","13","IEEE","13 Jul 2017","","","IEEE","IEEE Conferences"
"Recurrent TPS development issues or ascertaining the excellence of an automated unit test","L. V. Kirkland; C. N. McConkey","WesTest Engineering Corporation, Farmington, Utah; Weber State University, Ogden, Utah","2016 IEEE AUTOTESTCON","13 Oct 2016","2016","","","1","7","Although Test Program Set (TPS) development is a science; it can be construed as an ART if a precise software environment and exacting test program development practices are utilized. Also, the ability to build an effective and precise software development environment for TPS development is not an off-the-wall bunch of guesswork routines. This can only be accomplished by true test engineers who work in the test and diagnosis environment and understand the various requirements to develop a group of measurements that cover all of the aspects of a TPS. An advocate of true test technology, who wants a complete and comprehensive fault coverage of a Unit Under Test (UUT), will not be satisfied with mundane TPSs that are not capable of scoping out UUT failures is a precise, timely and factual manner. To scope out UUT problems requires practicing many factors which focus on TPS quality, robust software tools, powerful test hardware and the inclusion of state-of-the-art hardware with interactive diagnostics. Major TPS weaknesses continue to be diagnostics, manual probing, real life trends, time to repair, cross-referencing, weak test equipment, test time, etc. About 70% of the TPS development effort can go to diagnostics. Accurately estimated enhanced diagnostics can result in a substantial life-cycle cost savings. In fact, during TPS development and TPS support, fault localization should be the first step and always the most critical step. Ideally, there should be no more than 3-4 probes to (no probing is best) and fault isolate to 2 or less components with very high accuracy. UUT accessibility and thru-put complicate the TPS design and the UUT repairer. Complicated state transition sequences and edge changes can be a setback when trying to control the UUT circuits. We should always focus on what's really happening at some internal circuit element. The time to repair can be hindered by Fan Out, No-Fault-Found (NFF), Intermittents, UUT Source and sink circuits, noise with the Automatic Test equipment (ATE) or in the Interface Test Adapter (ITA), component weakness, miss-matched replacement parts, poor connections (solder / pins), component variations, etc. All elements are critical and time to repair can go into days and even weeks. There are clues to TPS weaknesses that dictate re-examination and reconsideration. These clues can include things like glitches, limits, % detect, test time, impedance, instrument selection, signal routing, ITA design, diagnostic issues, excessive code or software routines, ambiguity groups, signal degradation from various sources, signal amplification, signal reduction, lack of test requirements or data, improper grounding, noise, etc. TPS weaknesses need attention and improvement when they are observed. Support costs tend to compound when weaknesses are not corrected ASAP. This paper will cover many aspects associated with a TPS that fulfills the customer's needs and expectations and this includes the ATE and a focus on diagnostic issues.","1558-4550","978-1-5090-0790-5","10.1109/AUTEST.2016.7589643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589643","","Power system faults;Power system protection;Maintenance engineering;Testing;Software;Circuit faults;Computer bugs","automatic test equipment;fault diagnosis;program testing;programming environments;software fault tolerance;software tools","recurrent TPS development;automated unit test;test program set;test program development practices;software development environment;diagnosis environment;test technology;fault coverage;unit under test;UUT failures;TPS quality;software tools;test hardware;interactive diagnostics;life-cycle cost savings;fault localization;state transition sequences;UUT circuits;fan out;no-fault-found;NFF;UUT source;sink circuits;automatic test equipment;ATE;interface test adapter;ITA;component weakness;miss-matched replacement parts","","1","","3","IEEE","13 Oct 2016","","","IEEE","IEEE Conferences"
"Domain Adaptation for Test Report Classification in Crowdsourced Testing","J. Wang; Q. Cui; S. Wang; Q. Wang","Laboratory for Internet Software Technologies; Laboratory for Internet Software Technologies; Electrical and Computer Engineering, University of Waterloo, Canada; Laboratory for Internet Software Technologies","2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP)","3 Jul 2017","2017","","","83","92","In crowdsourced testing, it is beneficial to automatically classify the test reports that actually reveal a fault - a true fault, from the large number of test reports submitted by crowd workers. Most of the existing approaches toward this task simply leverage historical data to train a machine learning classifier and classify the new incoming reports. However, our observation on real industrial data reveals that projects under crowdsourced testing come from various domains, and the submitted reports usually contain different technical terms to describe the software behavior for each domain. The different data distribution across domains could significantly degrade the performance of classification models when utilized for cross-domain report classification. To build an effective cross-domain classification model, we leverage deep learning to discover the intermediate representation that is shared across domains, through the co-occurrence between domain-specific terms and domain-unaware terms. Specifically, we use the Stacked Denoising Autoencoders to automatically learn the high-level features from raw textual terms, and utilize these features for classification. Our evaluation on 58 commercial projects of 10 domains from one of the Chinese largest crowdsourced testing platforms shows that our approach can generate promising results, compared to three commonly-used and state-of-the-art baselines. Moreover, we also evaluate its usefulness using real-world case studies. The feedback from real-world testers demonstrates its practical value.","","978-1-5386-2717-4","10.1109/ICSE-SEIP.2017.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965432","Crowdsourced testing;test report classification;domain adaptation;deep learning","Testing;Feature extraction;Noise reduction;Training;Software;Data models;Machine learning","learning (artificial intelligence);pattern classification;program testing","test report classification;crowdsourced testing;machine learning classifier;stacked denoising autoencoders;data distribution;cross-domain report classification;deep learning","","15","","31","IEEE","3 Jul 2017","","","IEEE","IEEE Conferences"
"An Empirical Framework for Code Smell Prediction using Extreme Learning Machine","H. Gupta; L. Kumar; L. B. M. Neti","BITS Pilani Hyderabad Campus, India; BITS Pilani Hyderabad Campus, India; BITS Pilani Hyderabad Campus, India","2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON)","21 Oct 2019","2019","","","189","195","The software containing code smells indicates the violation of standard design and coding practices by developer during the development of the software system. Recent empirical studies observed that classes having code smells have higher probability of change proneness or fault proneness with respect to classes having no code smells [1]. The effort of removing bugs due to code smells increases exponentially if the smells are not identified during the earlier phases of software development. The code smell prediction using source code metrics can be used in starting phases of software development life cycle to reduce the maintenance and testing effort of software and also help in improving the quality of the software. The work in this paper empirically investigates and evaluates different classification techniques, feature selection techniques, and data sampling techniques to handle imbalance data in predicting 7 different types of code smell. The conclusion of this research is assessed over 629 application packages. The experimental finding confirms the estimating capability of different classifiers, feature selection, and data imbalance techniques for developing code smell prediction models. Our analysis also reveals that the models developed using one technique are superior than the models developed using other techniques.","","978-1-5386-9325-4","10.1109/IEMECONX.2019.8877082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877082","Code Smell;Software Engineering;Source Code Metrics;Machine Learning;Feature selection","Measurement;Analytical models;Codes;Predictive models;Feature extraction;Software systems;Software","feature selection;feedforward neural nets;pattern classification;program debugging;program testing;software fault tolerance;software maintenance;software metrics;software quality;source code (software)","coding practices;source code metrics;software development life cycle;code smell prediction models;extreme learning machine;change proneness;fault proneness;bugs removal;software maintenance;software testing;software quality;classification techniques;feature selection techniques;data sampling techniques;data imbalance techniques","","6","","10","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Research on Simplified Method of Combination Test Case Set for Basic Software System","W. Liu; J. Xiong","Software Quality Engineering Research Center, The 5th Electronics Research Institute of the Ministry of Information Industry of China, Guangzhou, China; Software Quality Engineering Research Center, The 5th Electronics Research Institute of the Ministry of Information Industry of China, Guangzhou, China","2020 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS)","22 Sep 2020","2020","","","718","721","The number of basic software products is excessive. If every kind of platform combination and every index of each combination is tested, there exists the problem of combination explosion, and the test cycle and cost increase rapidly. As a scientific and effective software testing method, combinatorial testing uses fewer test cases to detect the effects of the various factors of the software system and their interactions on the system effectively. It has been proved by practice that it has high error detection ability. In order to meet the test requirements with the minimal test case, this paper presents a test case set reduction method based on ant colony algorithm. Through abstracting each test case as an independent node, constructing virtual ant colony and updating the pheromone, the method is verified by the instance at last. The experimental results prove that the method is feasible and effective.","","978-1-7281-9874-3","10.1109/ICPICS50287.2020.9202225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9202225","basic software system;combination test case set;ant colony algorithm","Software algorithms;Software systems;Testing;Optimization;Distributed computing;Heuristic algorithms","ant colony optimisation;combinatorial mathematics;program testing","effective software testing method;combinatorial testing;high error detection ability;test requirements;minimal test case;test case set reduction method;combination test case set;basic software system;basic software products;combination explosion;test cycle;cost increase;scientific software testing method","","","","9","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"Constrained Interaction Testing: A Systematic Literature Study","B. S. Ahmed; K. Z. Zamli; W. Afzal; M. Bures","Software Testing Intelligent Laboratory, Czech Technical University in Prague, Prague, Czech Republic; Faculty of Computer Systems and Software Engineering, University Malaysia Pahang, Gambang, Malaysia; School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; Software Testing Intelligent Laboratory, Czech Technical University in Prague, Prague, Czech Republic","IEEE Access","7 Dec 2017","2017","5","","25706","25730","Interaction testing can be used to effectively detect faults that are otherwise difficult to find by other testing techniques. However, in practice, the input configurations of software systems are subjected to constraints, especially in the case of highly configurable systems. Handling constraints effectively and efficiently in combinatorial interaction testing is a challenging problem. Nevertheless, researchers have attacked this challenge through different techniques, and much progress has been achieved in the past decade. Thus, it is useful to reflect on the current achievements and shortcomings and to identify potential areas of improvements. This paper presents the first comprehensive and systematic literature study to structure and categorize the research contributions for constrained interaction testing. Following the guidelines of conducting a literature study, the relevant data are extracted from a set of 103 research papers belonging to constrained interaction testing. The topics addressed in constrained interaction testing research are classified into four categories of constraint test generation, application, generation and application, and model validation studies. The papers within each of these categories are extensively reviewed. Apart from answering several other research questions, this paper also discusses the applications of constrained interaction testing in several domains, such as software product lines, fault detection and characterization, test selection, security, and graphical user interface testing. This paper ends with a discussion of limitations, challenges, and future work in the area.","2169-3536","","10.1109/ACCESS.2017.2771562","Fundamental Research Grant: Reinforcement Learning Sine Cosine Based Strategy for Combinatorial Test Suite from the Ministry of Higher Education Malaysia(grant numbers:RDU170103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8102999","Constrained interaction testing;constrained combinatorial testing;software testing;test generation tools;test case design techniques","Systematics;Data mining;Software testing;Electronic mail;Software systems;Tools","fault diagnosis;graphical user interfaces;program testing;software development management;software fault tolerance","systematic literature study;constrained interaction testing research;constraint test generation;test selection;graphical user interface testing;testing techniques;combinatorial interaction testing;comprehensive literature study;software systems;software product lines;fault detection","","34","","138","OAPA","9 Nov 2017","","","IEEE","IEEE Journals"
"Evaluating Regression Test Selection Opportunities in a Very Large Open-Source Ecosystem","A. Gyori; O. Legunsen; F. Hariri; D. Marinov","Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA","2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE)","18 Nov 2018","2018","","","112","122","Regression testing in very large software ecosystems is notoriously costly, requiring computational resources that even large corporations struggle to cope with. Very large ecosystems contain thousands of rapidly evolving, interconnected projects where client projects transitively depend on library projects. Regression test selection (RTS) reduces regression testing costs by rerunning only tests whose pass/fail behavior may flip after code changes. For single projects, researchers showed that class-level RTS is more effective than lower method-or statement-level RTS. Meanwhile, several very large ecosystems in industry, e.g., at Facebook, Google, and Microsoft, perform project-level RTS, rerunning tests in a changed library and in all its transitive clients. However, there was no previous study of the comparative benefits of class-level and project-level RTS in such ecosystems. We evaluate RTS opportunities in the MAVEN Central open-source ecosystem. There, some popular libraries have up to 924589 clients; in turn, clients can depend on up to 11190 libraries. We sampled 408 popular projects and found that 202 (almost half) cannot update to latest library versions without breaking compilation or tests. If developers want to detect these breakages earlier, they need to run very many tests. We compared four variants of class-level RTS with project-level RTS in MAVEN Central. The results showed that class-level RTS may be an order of magnitude less costly than project-level RTS in very large ecosystems. Specifically, various class-level RTS variants select, on average, 7.8%-17.4% of tests selected by project-level RTS.","2332-6549","978-1-5386-8321-7","10.1109/ISSRE.2018.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539074","Regression Testing;Regression Test Selection;Ecosystem Testing","Libraries;Ecosystems;Testing;Google;Open source software;Industries","program testing;public domain software;regression analysis","regression test selection opportunities;library projects;project-level RTS;MAVEN Central open-source ecosystem;class-level RTS variants;regression testing cost reduction;software ecosystems;statement-level RTS","","12","","60","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"De-Flake Your Tests : Automatically Locating Root Causes of Flaky Tests in Code At Google","C. Ziftci; D. Cavalcanti","Google Inc., New York, USA; Google Inc., New York, USA","2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)","2 Nov 2020","2020","","","736","745","Regression testing is a critical part of software development and maintenance. It ensures that modifications to existing software do not break existing behavior and functionality.One of the key assumptions about regression tests is that their results are deterministic: when executed without any modifications with the same configuration, either they always fail or they always pass. In practice, however, there exist tests that are non-deterministic, called flaky tests. Flaky tests cause the results of test runs to be unreliable, and they disrupt the software development workflow. In this paper, we present a novel technique to automatically identify the locations of the root causes of flaky tests on the code level to help developers debug and fix them. We study the technique on flaky tests across 428 projects at Google. Based on our case studies, the technique helps identify the location of the root causes of flakiness with 82% accuracy. Furthermore, our studies show that integration into the appropriate developer workflows, simplicity of debugging aides and fully automated fixes are crucial and preferred components for adoption and usability of flakiness debugging and fixing tools.","2576-3148","978-1-7281-5619-4","10.1109/ICSME46990.2020.00083","Google; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240685","Software maintenance;Diagnostics;Debugging aids;Debuggers;Tracing;Test management;Flaky tests","Debugging;Tools;Maintenance engineering;Software;Internet;Usability;Testing","program debugging;program testing;regression analysis;software fault tolerance;software metrics","regression testing;software maintenance;regression tests;flaky tests;test runs;software development workflow;flakiness debugging;fixing tools;Google","","14","","48","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Canopus: A Domain-Specific Language for Modeling Performance Testing","M. Bernardino; A. F. Zorzo; E. M. Rodrigues","Postgraduate Program in Computer Science, Pontifical Catholic University of Rio Grande do Sul (PUCRS), Porto Alegre, RS, Brazil; Postgraduate Program in Computer Science, Pontifical Catholic University of Rio Grande do Sul (PUCRS), Porto Alegre, RS, Brazil; Postgraduate Program in Computer Science, Pontifical Catholic University of Rio Grande do Sul (PUCRS), Porto Alegre, RS, Brazil","2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)","21 Jul 2016","2016","","","157","167","Despite all the efforts to reduce the cost of the testing phase in software development, it is still one of the most expensive phases. In order to continue to minimize those costs, in this paper, we propose a Domain-Specific Language (DSL), built on top of MetaEdit+ language workbench, to model performance testing for web applications. Our DSL, called Canopus, was developed in the context of a collaboration1 between our university and a Technology Development Laboratory (TDL) from an Information Technology (IT) company. We present, in this paper, the Canopus metamodels, its domain analysis, a process that integrates Canopus to Model-Based Performance Testing, and applied it to an industrial case study.","","978-1-5090-1827-7","10.1109/ICST.2016.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515468","performance testing;domain-specific language;domain-specific modeling;model-based testing","Testing;DSL;Unified modeling language;Analytical models;Load modeling;Computational modeling;Automation","Internet;program testing;software cost estimation;specification languages","domain-specific language;performance testing modeling;cost reduction;software development testing;cost minimization;DSL;MetaEdit+ language workbench;Web applications;technology development laboratory;TDL;information technology company;IT company;Canopus metamodels;model-based performance testing","","8","1","32","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"An Empirical Comparison of Similarity Measures for Abstract Test Case Prioritization","R. Huang; Y. Zhou; W. Zong; D. Towey; J. Chen","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China; T School of Computer Science, The University of Nottingham Ningbo China, Ningbo, P.R. China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China","2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)","11 Sep 2017","2017","1","","3","12","Test case prioritization (TCP) attempts to order test cases such that those which are more important, according to some criterion or measurement, are executed earlier. TCP has been applied in many testing situations, including, for example, regression testing. An abstract test case (also called a model input) is an important type of test case, and has been widely used in practice, such as in configurable systems and software product lines. Similarity-based test case prioritization (STCP) has been proven to be cost-effective for abstract test cases (ATCs), but because there are many similarity measures which could be used to evaluate ATCs and to support STCP, we face the following question: How can we choose the similarity measure(s) for prioritizing ATCs that will deliver the most effective results? To address this, we studied fourteen measures and two popular STCP algorithms - local STCP (LSTCP), and global STCP (GSTCP). We also conducted an empirical study of five realworld programs, and investigated the efficacy of each similarity measure, according to the interaction coverage rate and fault detection rate. The results of these studies show that GSTCP outperforms LSTCP - in 61% to 84% of the cases, in terms of interaction coverage rates; and in 76% to 78% of the cases with respect to fault detection rates. Our studies also show that Overlap, the simplest similarity measure examined in this study, could obtain the overall best performance for LSTCP; and that Goodall3 has the best performance for GSTCP.","0730-3157","978-1-5386-0367-3","10.1109/COMPSAC.2017.271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029584","Software testing;test case prioritization;abstract test case;similarity","Testing;Fault detection;Software;Computer science;Software product lines;Fault diagnosis;Algorithm design and analysis","program testing","global STCP;local STCP;ATC;abstract test case prioritization;similarity measures","","7","","25","IEEE","11 Sep 2017","","","IEEE","IEEE Conferences"
"Transitioning from Manual to Automated Software Regression Testing: Experience from the Banking Domain","A. Akin; S. Sentürk; V. Garousi","Research and Development (R&D) Center, Kuveyt Türk Participation Bank Inc., Turkey; Research and Development (R&D) Center, Kuveyt Türk Participation Bank Inc., Turkey; Research and Development (R&D) Center, Kuveyt Türk Participation Bank Inc., Turkey","2018 25th Asia-Pacific Software Engineering Conference (APSEC)","23 May 2019","2018","","","591","597","Regression testing is needed when a software or the environment hosting that software changes. Motivated by a real-world industrial need in the context of a large financial (banking) corporation in Turkey, the authors and their colleagues developed and introduced an automated regression testing infrastructure for automated testing of one of the main mobile applications of the company. Before this project, regression testing was conducted manually which incurred a lot of costs and was by nature subjective. We report in this paper our experience in ""transitioning"" from manual to automated regression testing, and in developing and introducing a set of large automated test suites (more than 16 KLOC in total), using best practices in state-of-the art and -practice, and to report its observed benefits by conducting cost-benefit analysis. The project was conducted based on the principles of case-study and ""action research"" in which the real industrial needs drove the research. Among the best practices that we used are the followings: (1) modularity in test code, (2) creating test-specific libraries, and (3) separating test data from test logic. By serving as a success story and experience report in development and introduction of automated test suites in an industrial setting, this paper adds to the body of evidence in this area and it aims at sharing both technical (e.g., using automated test patterns) and process aspects (e.g., test process improvement) from our project with other practitioners and researchers.","2640-0715","978-1-7281-1970-0","10.1109/APSEC.2018.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719455","Software testing;regression testing;test automation;experience report;mobile software","Testing;Automation;Software;Companies;Tools;Manuals;Banking","bank data processing;cost-benefit analysis;mobile computing;program testing;regression analysis;software libraries","test code;automated software regression testing;banking domain;financial corporation;cost-benefit analysis;creating test-specific libraries;test data separation;Turkey;mobile applications;industrial needs","","3","","39","IEEE","23 May 2019","","","IEEE","IEEE Conferences"
"Improving Testing in an Enterprise SOA with an Architecture-Based Approach","G. Buchgeher; C. Klammer; W. Heider; M. Schüetz; H. Huber","Software Competence Center Hagenberg, Hagenberg, Austria; Software Competence Center Hagenberg, Hagenberg, Austria; Raiffeisen Software GmbH, Linz, Austria; Raiffeisen Software GmbH, Linz, Austria; Raiffeisen Software GmbH, Linz, Austria","2016 13th Working IEEE/IFIP Conference on Software Architecture (WICSA)","21 Jul 2016","2016","","","231","240","High resource demand for system testing is a major obstacle for continuous delivery. This resource demand can be reduced by prioritizing test cases, e.g., by focusing on tests that cover a lot of functionality. For large-scale systems, like an enterprise SOA, defining such test cases can be difficult for the tester because of the lack of relevant knowledge about the system. We propose an approach for test case prioritization and selection that is based on architectural viewpoint that provides software testers with the required architectural information. We outline how architectural information is used for defining and selecting prioritized test cases. The approach has been developed in close cooperation with the provider of an enterprise SOA in the banking domain in Austria following an action research approach. In addition, the approach has been validated in an industrial case study. Validation showed that there is no further need for manual architectural analysis to be able to prioritize and select test cases. We also show the limitations of our approach as it is based on static code analysis.","","978-1-5090-2131-4","10.1109/WICSA.2016.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516833","Test Management;Testing;Test Case Prioritization;SOA;Architecture Knowledge;Architecture-based Testing","Computer architecture;Testing;Service-oriented architecture;Semiconductor optical amplifiers;Business","program diagnostics;program testing;service-oriented architecture","static code analysis;action research approach;Austria;banking domain;software architectural information;software testers;test case selection;test case prioritization;system testing;enterprise SOA","","3","","24","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"Assessing Test Case Prioritization on Real Faults and Mutants","Q. Luo; K. Moran; D. Poshyvanyk; M. Di Penta","Department of Computer Science, College of William & Mary, Williamsburg, VA; Department of Computer Science, College of William & Mary, Williamsburg, VA; Department of Computer Science, College of William & Mary, Williamsburg, VA; Department of Engineering, University of Sannio, Benevento, Italy","2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)","11 Nov 2018","2018","","","240","251","Test Case Prioritization (TCP) is an important component of regression testing, allowing for earlier detection of faults or helping to reduce testing time and cost. While several TCP approaches exist in the research literature, a growing number of studies have evaluated them against synthetic software defects, called mutants. Hence, it is currently unclear to what extent TCP performance on mutants would be representative of the performance achieved on real faults. To answer this fundamental question, we conduct the first empirical study comparing the performance of TCP techniques applied to both real-world and mutation faults. The context of our study includes eight well-studied TCP approaches, 35k+ mutation faults, and 357 real-world faults from five Java systems in the Defects4J dataset. Our results indicate that the relative performance of the studied TCP techniques on mutants may not strongly correlate with performance on real faults, depending upon attributes of the subject programs. This suggests that, in certain contexts, the best performing technique on a set of mutants may not be the best technique in practice when applied to real faults. We also illustrate that these correlations vary for mutants generated by different operators depending on whether chosen operators reflect typical faults of a subject program. This highlights the importance, particularly for TCP, of developing mutation operators tailored for specific program domains.","2576-3148","978-1-5386-7870-1","10.1109/ICSME.2018.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530033","Test Case Prioritization;Empirical Study;TCP;Mutation Analysis;Mutation Testing;Mutants","Testing;Software;Fault detection;Genetic algorithms;Correlation;Measurement;Data mining","Java;program testing;regression analysis;software fault tolerance","studied TCP techniques;typical faults;test case prioritization;regression testing;testing time;synthetic software defects;well-studied TCP approaches;real-world faults;Defects4J dataset;TCP performance;mutation faults","","28","","80","IEEE","11 Nov 2018","","","IEEE","IEEE Conferences"
"Some Thoughts on Model-Based Test Optimization","P. Liu; Y. Li; Z. Li","Engineering Research Center for Software Testing and Evaluation of Fujian Province, Fujian, China; Shanghai Business School, Shanghai, China; Department of Industrial Engineering and Engineering Management, Western New England University, USA","2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)","7 Oct 2019","2019","","","268","274","As a test method, model-based testing has been proven to have the ability to find inconsistencies between a software system and its design model and objectives. Because the design of the model is independent of the development of program codes, the generation of test cases from the model is synchronized with the development of software codes, saving the software test cost. This paper reviews the development of model-based test methods from the optimization perspective and presents five issues in the test optimization process. In addition, the paper discusses four types of optimization strategies for reducing the redundancy of test sequences and an optimization method by using the regular expression model. Finally, this paper gives two potential research directions, including model optimization and software bug location in the program, for model-based testing in the future. This research contributes to the applications of model-based testing in industry.","","978-1-7281-3925-8","10.1109/QRS-C.2019.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859442","test optimization;model-based testing;redundancy reduction;model optimization","Software;Optimization;Automata;Unified modeling language;Object oriented modeling;Software testing","optimisation;program debugging;program testing","test optimization process;test sequences;optimization method;regular expression model;model optimization;software bug location;model-based testing;model-based test optimization;test method;design model;software test cost;model-based test methods;software codes development;optimization strategies","","5","","75","IEEE","7 Oct 2019","","","IEEE","IEEE Conferences"
"Design and implementation of bank financial business automation testing framework based on QTP","X. Xie; Z. Yang; J. Yu; W. Zhang","School of Information Yunnan, University of Finance and Economics, Kunming, China; School of Infomation, Yunnan University Kunming, Kunming, China; School of Information, Yunnan University of Finance and Economics, Kunming, Yunnan, CN; School of Infomation, Yunnan University Kunming, Kunming, China","2016 5th International Conference on Computer Science and Network Technology (ICCSNT)","19 Oct 2017","2016","","","143","147","The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.","","978-1-5090-2129-1","10.1109/ICCSNT.2016.8070136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070136","software testing;test automation framework;QTP automated testing tool","Testing;Software;Tools;Automation;Standardization;Object recognition;Libraries","bank data processing;object recognition;program testing;software quality;software reliability","object recognition;software reliability;software quality;banking service;bank financial business automation testing framework;financial services;software scale;software technology;domestic financial bank;software automation testing;test cost;testing framework design;test standardization;test system design;business-level testing;keyword-driven technology;regression testing;online banking;QTP;third-party testing tools;software testing industry;automated testing technology","","2","","17","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"A Logistic Regression Based Approach for Software Test Management","Y. Zhou; J. Yan","School of Information and Engineering, Communication Univercity of China, Beijing, China; MOE, Communication Univercity of China, Beijing, China","2016 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)","28 Feb 2017","2016","","","268","271","Software test management is a hot field of software engineering both in academia and industry. However, traditional research are focused on software quality rather than test quality which could be evaluated by test management. Meanwhile, previous works on evaluating software test management were mostly based on statistical methods. In recently years, machine learning algorithms and techniques are developing rapidly. Logistic Regression is one of the important and often used algorithms. It is widely used in many domains such as credit investigation, book classification and so on. Therefore, our objective is to establish a logistic regression based approach for software test management to evaluate test quality. In this paper, we introduce our methodology to build metrics framework for test management, and enumerate the definition, type and range of each metric. We also show some results of our experiments using some data samples from a huge data sets.","","978-1-5090-5154-0","10.1109/CyberC.2016.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7864244","test management;logistic regression;test quality","Software;Logistics;Testing;Total quality management;Mathematical model;Software measurement","logistics data processing;program testing;regression analysis;software management;software quality","logistic regression;software test management;software engineering;academia;industry;software quality;statistical methods;metric framework;data samples;huge data sets","","2","","7","IEEE","28 Feb 2017","","","IEEE","IEEE Conferences"
"Quality Assessment for Large-Scale Industrial Software Systems: Experience Report at Alibaba","C. Zhi; S. Deng; J. Yin; M. Fu; H. Zhu; Y. Li; T. Xie","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Ministry of Education, Key Laboratory of High Confidence Software Technologies (Peking University), China","2019 26th Asia-Pacific Software Engineering Conference (APSEC)","2 Jan 2020","2019","","","142","149","To assure high software quality for large-scale industrial software systems, traditional approaches of software quality assurance, such as software testing and performance engineering, have been widely used within Alibaba, the world's largest retailer, and one of the largest Internet companies in the world. However, there still exists a high demand for software quality assessment to achieve high sustainability of business growth and engineering culture in Alibaba. To address this issue, we develop an industrial solution for software quality assessment by following the GQM paradigm in an industrial setting. Moreover, we integrate multiple assessment methods into our solution, ranging from metric selection to rating aggregation. Our solution has been implemented, deployed, and adopted at Alibaba: (1) used by Alibaba's Business Platform Unit to continually monitor the quality for 60+ core software systems; (2) used by Alibaba's R&D Efficiency Unit to support group-wide quality-aware code search and automatic code inspection. This paper presents our proposed industrial solution, including its techniques and industrial adoption, along with the lessons learned during the development and deployment of our solution.","2640-0715","978-1-7281-4648-5","10.1109/APSEC48747.2019.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945717","software quality assessment;software quality model;experience report","Software quality;Business;Software systems;Software metrics;Adaptation models","Internet;program testing;quality assurance;retailing;software metrics;software quality;source code (software)","large-scale industrial software systems;software quality assurance;software testing;Internet companies;software quality assessment;sustainability;business growth;engineering culture;industrial solution;industrial setting;group-wide quality-aware code search;Alibaba R&D Efficiency Unit;Alibaba Business Platform Unit;performance engineering;retailer;GQM paradigm;rating aggregation;metric selection;automatic code inspection","","2","","27","IEEE","2 Jan 2020","","","IEEE","IEEE Conferences"
"Will My Tests Tell Me If I Break This Code?","R. Niedermayr; E. Juergens; S. Wagner","CQSE GmbH Garching b. München, Germany; CQSE GmbH Garching b. München, Germany; University of Sfuttgart Stuttgart, Germany","2016 IEEE/ACM International Workshop on Continuous Software Evolution and Delivery (CSED)","9 Jan 2017","2016","","","23","29","Automated tests play an important role in software evolution because they can rapidly detect faults introduced during changes. In practice, code-coverage metrics are often used as criteria to evaluate the effectiveness of test suites with focus on regression faults. However, code coverage only expresses which portion of a system has been executed by tests, but not how effective the tests actually are in detecting regression faults. Our goal was to evaluate the validity of code coverage as a measure for test effectiveness. To do so, we conducted an empirical study in which we applied an extreme mutation testing approach to analyze the tests of open-source projects written in Java. We assessed the ratio of pseudo-tested methods (those tested in a way such that faults would not be detected) to all covered methods and judged their impact on the software project. The results show that the ratio of pseudo-tested methods is acceptable for unit tests but not for system tests (that execute large portions of the whole system). Therefore, we conclude that the coverage metric is only a valid effectiveness indicator for unit tests.","","978-1-4503-4157-8","10.1145/2896941.2896944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809431","Regression Testing;Test Suite Effectiveness;Code Coverage;Mutation Testing","Testing;Measurement;Open source software;Java;Production facilities;Correlation","fault diagnosis;Java;program debugging;program testing;public domain software;regression analysis;software maintenance;software metrics","software testing;automated testing;software evolution;code-coverage metrics;regression fault detection;code coverage validity evaluation;test effectiveness measure;extreme mutation testing;open-source project;Java;software project","","5","","13","","9 Jan 2017","","","IEEE","IEEE Conferences"
"Experience Report: Automated System Level Regression Test Prioritization Using Multiple Factors","P. E. Strandberg; D. Sundmark; W. Afzal; T. J. Ostrand; E. J. Weyuker","Westermo Research and Development AB, Västerås, Sweden; Mälardalen University, Västerås, Sweden; Mälardalen University, Västerås, Sweden; Mälardalen University, Västerås, Sweden; Mälardalen University, Västerås, Sweden","2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE)","8 Dec 2016","2016","","","12","23","We propose a new method of determining an effective ordering of regression test cases, and describe its implementation as an automated tool called SuiteBuilder developed by Westermo Research and Development AB. The tool generates an efficient order to run the cases in an existing test suite by using expected or observed test duration and combining priorities of multiple factors associated with test cases, including previous fault detection success, interval since last executed, and modifications to the code tested. The method and tool were developed to address problems in the traditional process of regression testing, such as lack of time to run a complete regression suite, failure to detect bugs in time, and tests that are repeatedly omitted. The tool has been integrated into the existing nightly test framework for Westermo software that runs on large-scale data communication systems. In experimental evaluation of the tool, we found significant improvement in regression testing results. The re-ordered test suites finish within the available time, the majority of fault-detecting test cases are located in the first third of the suite, no important test case is omitted, and the necessity for manual work on the suites is greatly reduced.","2332-6549","978-1-4673-9002-6","10.1109/ISSRE.2016.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7774503","","Testing;Topology;Ports (Computers);Manuals;Hardware;Software;Research and development","data communication;fault diagnosis;program testing;regression analysis;statistical testing","automated system level regression test prioritization;SuiteBuilder;fault detection success;regression testing process;Westermo software;large-scale data communication systems;fault-detection test;software testing","","15","","22","IEEE","8 Dec 2016","","","IEEE","IEEE Conferences"
"iTES: Integrated Testing and Evaluation System for Software Vulnerability Detection Methods","C. Zhang; J. Chen; S. Cai; B. Liu; Y. Wu; Y. Geng","Jiangsu University, School of Computer Science and Communication Engineering, Zhenjiang, China; Jiangsu University, School of Computer Science and Communication Engineering, Zhenjiang, China; Jiangsu University, School of Computer Science and Communication Engineering, Zhenjiang, China; Jiangsu University, School of Computer Science and Communication Engineering, Zhenjiang, China; Jiangsu University, School of Computer Science and Communication Engineering, Zhenjiang, China; Jiangsu University, School of Computer Science and Communication Engineering, Zhenjiang, China","2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Feb 2021","2020","","","1455","1460","To find software vulnerabilities using software vulnerability detection technology is an important way to ensure the system security. Existing software vulnerability detection methods have some limitations as they can only play a certain role in some specific situations. To accurately analyze and evaluate the existing vulnerability detection methods, an integrated testing and evaluation system (iTES) is designed and implemented in this paper. The main functions of the iTES are:(1) Vulnerability cases with source codes covering common vulnerability types are collected automatically to form a vulnerability cases library; (2) Fourteen methods including static and dynamic vulnerability detection are evaluated in iTES, involving the Windows and Linux platforms; (3) Furthermore, a set of evaluation metrics is designed, including accuracy, false positive rate, utilization efficiency, time cost and resource cost. The final evaluation and test results of iTES have a good guiding significance for the selection of appropriate software vulnerability detection methods or tools according to the actual situation in practice.","2324-9013","978-1-6654-0392-4","10.1109/TrustCom50675.2020.00196","National Natural Science Foundation of China (NSFC)(grant numbers:U1836116,61762040,61872167); Graduate Research Innovation Project of Jiangsu Province(grant numbers:KYCX17_1807); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343154","software vulnerability detection;information security;evaluation method;test platform","Linux;Tools;Software;Time measurement;Security;Indexes;Testing","Linux;program testing;safety-critical software","vulnerability case library;integrated testing and evaluation system;appropriate software vulnerability detection methods;evaluation metrics;dynamic vulnerability detection;static vulnerability detection;system security;software vulnerability detection technology;iTES","","","","26","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"Adaptive Partition Testing","C. -A. Sun; H. Dai; H. Liu; T. Y. Chen; K. -Y. Cai","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; College of Engineering and Science, Victoria University, Melbourne, VIC, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","IEEE Transactions on Computers","13 Jan 2019","2019","68","2","157","169","Random testing and partition testing are two major families of software testing techniques. They have been compared both theoretically and empirically in numerous studies for decades, and it has been widely acknowledged that they have their own advantages and disadvantages and that their innate characteristics are fairly complementary to each other. Some work has been conducted to develop advanced testing techniques through the integration of random testing and partition testing, attempting to preserve the advantages of both while minimizing their disadvantages. In this paper, we propose a new testing approach, adaptive partition testing, where test cases are randomly selected from some partition whose probability of being selected is adaptively adjusted along the testing process. We particularly develop two algorithms, Markov-chain based adaptive partition testing and reward-punishment based adaptive partition testing, to implement the proposed approach. The former algorithm makes use of Markov matrix to dynamically adjust the probability of a partition to be selected for conducting tests; while the latter is based on a reward and punishment mechanism. We conduct empirical studies to evaluate the performance of the proposed algorithms using ten faulty versions of three large-scale open source programs. Our experimental results show that, compared with two baseline techniques, namely random partition testing (RPT) and dynamic random testing (DRT), our algorithms deliver higher fault-detection effectiveness with lower test case selection overhead. It is demonstrated that the proposed adaptive partition testing is an effective testing approach, taking advantages of both random testing and partition testing.","1557-9956","","10.1109/TC.2018.2866040","Beijing Municipal Natural Science Foundation(grant numbers:4162040); National Natural Science Foundation of China(grant numbers:61872039); Aeronautical Science Foundation of China(grant numbers:2016ZD74004); Fundamental Research Funds for the Central Universities(grant numbers:FRF-GF-17-B29); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440117","Random testing;partition testing;adaptive partition testing","Software testing;Markov processes;Probability;Statistical analysis","Markov processes;probability;program testing;statistical testing","software testing techniques;advanced testing techniques;test cases;testing process;Markov-chain based adaptive partition testing;reward-punishment based adaptive partition testing;random partition testing;dynamic random testing;lower test case selection;effective testing approach","","9","","35","IEEE","19 Aug 2018","","","IEEE","IEEE Journals"
"A Cost-Effective Random Testing Method for Programs with Non-Numeric Inputs","A. C. Barus; T. Y. Chen; F. -C. Kuo; H. Liu; R. Merkel; G. Rothermel","Institut Teknologi Del, Kab Toba Samosir 22381, Sumatera Utara, Indonesia; Swinburne University of Technology, Hawthorn, VIC, Australia; Swinburne University of Technology, Hawthorn, VIC, Australia; Australia-India Research Centre for Automation Software Engineering, RMIT University, Melbourne, VIC, Australia; Monash University, Clayton, VIC, Australia; Department of Computer Science and Engineering, University of Nebraska - Lincoln, Lincoln, NC, NE","IEEE Transactions on Computers","4 Nov 2016","2016","65","12","3509","3523","Random testing (RT) has been widely used in the testing of various software and hardware systems. Adaptive random testing (ART) is a family of random testing techniques that aim to enhance the failure-detection effectiveness of RT by spreading random test cases evenly throughout the input domain. ART has been empirically shown to be effective on software with numeric inputs. However, there are two aspects of ART that need to be addressed to render its adoption more widespread-applicability to programs with nonnumeric inputs, and the high computation overhead of many ART algorithms. We present a linear-order ART algorithm for software with non-numeric inputs. The key requirement for using ART with non-numeric inputs is an appropriate “distance” measure. We use the concepts of categories and choices from category-partition testing to formulate such a measure. We investigate the failure-detection effectiveness of our technique by performing an empirical study on 14 object programs, using two standard metrics-F-measure and P-measure. Our ART algorithm statistically significantly outperforms RT on 10 of the 14 programs studied, and exhibits performance similar to RT on three of the four remaining programs. The selection overhead of our ART algorithm is close to that of RT.","1557-9956","","10.1109/TC.2016.2547380","Air Force Office of Scientific Research(grant numbers:FA9550-10-1-0406); University of Nebraska; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442567","Random testing;adaptive random testing;category-partition method","Subspace constraints;Random processes;Power capacitors;Software algorithms;Testing;Failure analysis","program testing;random processes","programs with nonnumeric inputs;software systems testing;hardware systems testing;adaptive random testing;RT failure-detection effectiveness;linear-order ART algorithm;software with nonnumeric inputs;category-partition testing;F-measure metrics;P-measure metrics","","19","","30","IEEE","28 Mar 2016","","","IEEE","IEEE Journals"
"Toward a New Methodology for an Efficient Test of Reconfigurable Hardware Systems","A. Ben Ahmed; O. Mosbahi; M. Khalgui; Z. Li","Tunisia Polytechnic School, University of Carthage, Tunis, Tunisia; National Institute of Applied Sciences and Technology, University of Carthage, Tunis, Tunisia; School of Electrical and Information Engineering, Jinan University (Zhuhai Campus), Zhuhai, China; School of Electro-Mechanical Engineering, Xidian University, Xi’an, China","IEEE Transactions on Automation Science and Engineering","4 Oct 2018","2018","15","4","1864","1882","This paper deals with the test of a reconfigurable hardware system (RHS). The latter is a hardware device that allows to change the hardware resources at runtime in order to modify the system functions and therefore to dynamically adapt the system to its environment. The increasing functional complexity of embedded systems and the transition to the RHS make the hardware testing a challenging task, especially under the confine of providing a high quality with a low cost. Considering the fact that the hardware test represents a key cost factor in a production process, an optimal test strategy can be advantageous in the competitive industrial market. Accordingly, this paper introduces a new methodology for an efficient hardware test of RHS. For an RHS, the number of stuck-at faults can be very large, which leads to a significant slowdown in the testing process. Because of the redundancy of faults between the different circuits composing an RHS, the proposed methodology aims at minimizing the number of faults using the inter-circuits relationships and consequently at providing an optimal fault set that can be effectively used for testing. Efficient techniques for test generation and test set validation are proposed to provide the test patterns for faults reduced by inter-circuits fault collapsing. The application of the generated test patterns is typically sufficient to provide an overall fault coverage. The proposed methodology is implemented in a new visual environment named TnTest. An experimental study confirms and validates the expected findings. Note to Practitioners-This paper addresses possible challenges for future generations of adaptive embedded systems. It proposes an original methodology for an efficient reconfigurable hardware system (RHS) hardware test. The main objective is to significantly reduce time and cost needed for the testing process. For an RHS, the number of stuck-at faults can be very large, which can cause a major slowdown in the hardware test. Based on the inter-circuits relations existing between the different circuits composing an RHS, the proposed methodology decreases considerably not only the number of the faults but also the test patterns needed for testing. The application of the generated test patterns is typically sufficient to provide an overall fault coverage. The proposed methodology is implemented in a new visual software environment named TnTest, which is capable of providing the smallest fault set as well as the efficient test set that can be effectively used for testing. This environment can be applied to test any embedded device that can be deployed in any new application based on flexible technologies. It can also be useful in manufacturing industries for a required improvement of the production process in relation to time and cost.","1558-3783","","10.1109/TASE.2018.2822050","Science and Technology Development Fund(grant numbers:078/2015/A3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353199","Automatic test pattern generation (ATPG);embedded system;fault collapsing;optimized test and validation;reconfiguration;scan","Reconfigurable architectures;Hardware;Testing;Automatic test pattern generation;Embedded systems","automatic test pattern generation;embedded systems;fault diagnosis;fault simulation;logic circuits;logic testing;program testing;reconfigurable architectures","RHS;hardware device;hardware resources;hardware testing;optimal test strategy;optimal fault set;inter-circuits fault collapsing;generated test patterns;adaptive embedded systems;reconfigurable hardware system;TnTest","","11","","42","IEEE","1 May 2018","","","IEEE","IEEE Journals"
"A Fast Regression Testing Method Using for EMS System Engineering Project","X. Kai; S. Chao","Institute of of NR Electric Co., Ltd, Nanjing, China; Institute of of NR Electric Co., Ltd, Nanjing, China","2016 Third International Conference on Trustworthy Systems and their Applications (TSA)","12 Dec 2016","2016","","","108","111","EMS(Energy Management System) is a software system with complex structure, which is used in power grid dispatching automation. In the life cycle of the system, it will go through a number of tests, such as FAT(factory test), SAT(acceptance test), etc, whose test cases will be as many as ten thousand. In the maintenance of EMS system, requirements may be often changed, which motivates the component modification to create new versions and their accompany tests. Regression testing strategies aim at the retest for modification affection in EMS software maintenance. This paper presents a EMS system regression testing method based on a new Component Testing Association Model. In this method, previously executed test cases are selected to generate the minimal regression test suite by the identification and impact analysis for the modification-affected component groups. Compared with traditional methods, our approach focus on the complicated interaction between components, which is more applicable to component system regression testing. Our method greatly saves the EMS system regression testing costs which go through the functional adjustment. In practical projects the execution of a moderate scale regression test was reduced by about 2 weeks.","","978-1-5090-3539-7","10.1109/TSA.2016.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780233","Ems system;regression test","","energy management systems;power grids;program testing;software maintenance;systems engineering","modification-affected component groups;minimal regression test suite generation;component testing association model;EMS system regression testing method;EMS software maintenance;component modification;acceptance test;SAT;factory test;FAT;software system life cycle;power grid dispatching automation;energy management system;EMS system engineering project","","","","9","IEEE","12 Dec 2016","","","IEEE","IEEE Conferences"
"Development of information exchange of software and hardware tools of system of test of difficult scientific-technical objects","V. V. Guchuk","V. A. Trapeznikov Institute of Control Sciences of Russian Academy of Sciences, Academy of Sciences, Moscow, Russia","2017 Tenth International Conference Management of Large-Scale System Development (MLSD)","16 Nov 2017","2017","","","1","5","The issues of software and hardware development are considered of data logging into systems of testing complex objects. The describes the architecture of a system for testing complex scientific-technical objects. In the list of original elements of the concept of building highly reliable, fast-reconfigurable interactive test monitoring and control systems: - using of original technology of representation dynamic parameters of the current process of test management for the process to simplify the process of making reasonable and effective operational decisions; - using of classification analysis algorithms (for determining the periodicity in the study of the rhythmic structure of complex signals) that increase the informative of the parametric estimates obtained; - using of hierarchically detailed 3-D representations to the operator of the state of the control system and the object under test; - using of methods and algorithms for preemptive criterial adaptation for guaranteed preservation of controllability conditions and prevention of abnormal conditions; - using of the method of modeling the process of targeted selection and making decisions on the evaluation of test results, based on a structurally linked set of requirements for the characteristics of the evaluated objects. In the work, some aspects of the development of the interconnection of software and hardware for providing data logging during testing of complex objects, including for diagnosing and forecasting work processes with the purpose of preventing the development of emergency situations, are sketched out.","","978-1-5386-0798-5","10.1109/MLSD.2017.8109636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109636","data stream;software and hardware tools;scientific-technical object;emergency situation;data logging;interactive mode","Testing;Databases;Process control;Hardware;Software;Control systems;Sensors","control engineering computing;data analysis;decision making;program testing;quality control;software engineering;software reliability","classification analysis algorithms;complex signals;control system;controllability conditions;software;data logging;information exchange;hardware tools;scientific-technical objects;hardware development;original elements;fast-reconfigurable interactive test monitoring;control systems;representation dynamic parameters;test management;3D representations;complex objects;operational decisions;forecasting work processes","","","","16","IEEE","16 Nov 2017","","","IEEE","IEEE Conferences"
"HoliCoW: Automatically Breaking Team-Based Software Projects to Motivate Student Testing","P. Zhang; J. White; D. C. Schmidt","Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","23 Mar 2017","2016","","","436","439","Intensive testing is often applied by professional software engineers to assure the quality of enterprise information technology (IT) systems. For example, Netflix's Simian Army consists of services that generate various types of failures, detect abnormal conditions, and test the ability of cloud-based enterprise IT software to survive them. Although software engineering students should be taught these types of rigorous testing techniques, it is often hard to motivate students to produce high-quality test suites for their assignments since classroom environments lack the harsh outcomes of unexpected system failures. This paper provides two contributions to work on strengthening coding and testing skills of software engineering students by aligning educational environment more closely with real-world industries. First, we describe the Holistic Code-Wrecker (HoliCoW), which is our testing method and tool that simulates production environments through forced logical error injections into student projects. The modified versions are then run against regression tests written by students, and the test results are analyzed to determine the robustness of original software. Second, this paper describes preliminary results from our ongoing experience applying HoliCoW to Software Engineering project courses at Vanderbilt University, where the tool is used to automatically evaluate student software project submissions to determine whether regression tests they define detect errors injected into their code.","","978-1-4503-4205-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883330","Software engineering education;software testing;software error injection","Software;Testing;Software engineering;Production;Software reliability;Hardware","computer science education;educational courses;educational institutions;program testing","HoliCoW;enterprise information technology systems;IT system quality assurance;cloud-based enterprise IT software testing;team-based software projects;student testing;classroom environments;software engineering students;educational environment;holistic code-wrecker;production environments;forced logical error injections;regression tests;software engineering project courses;Vanderbilt University","","1","","5","","23 Mar 2017","","","IEEE","IEEE Conferences"
"Simulator for intelligent software testing technique employing the most effective resource allocation algorithm for simultaneous optimization of software quality and release schedule","B. Sharma; S. K. Sharma","G.N. Girls College, Yamunanagar, India; Yamunanagar, India","2016 2nd International Conference on Next Generation Computing Technologies (NGCT)","16 Mar 2017","2016","","","600","607","An idea or a concept can be classified as transformational, operational or tactical. In the recent past, there have been more rational developments in software testing techniques outsmarting the ones prevailing earlier which weighed more in favor of empirical rather than logical aspects of software testing. This paper presents one of a kind of developments in software testing methodologies that were motivated by Operations Research modeling and describes in considerable detail the applicability of one of these models with regard to (w.r.t.) the application of available resources for optimizing the software quality metrics while adhering to the release schedule as well. The paper introduces a new and pioneering concept what we call Intelligent Software Testing (IST) technique which is not only transformational but operational and tactical as well. It examines areas and opportunities and utilizes them to make informed decisions w.r.t. the allocation of tasks where systems involving software testing can be improved, from design to delivery. The IST proposed herein undertakes two-way optimization w.r.t. competence and efficiency. It not only promises but delivers highest standard of software quality level by maximizing team competence and commitment to keep a date with the release schedule by minimizing activity time, both being crucial to software testing phenomenon.","","978-1-5090-3257-0","10.1109/NGCT.2016.7877484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877484","Intelligent software testing;most effective resource allocation (MERA);rank cost resonance (RCR);resource rank matrix (RRM)","Software testing;Resource management;Software quality;Schedules;Computers","optimisation;program testing;resource allocation;scheduling;software metrics;software quality","intelligent software testing technique;resource allocation algorithm;simultaneous software quality optimization;simultaneous release schedule optimization;operations research modeling;software quality metrics;IST technique;two-way optimization;team competence maximization;team commitment maximization;activity time minimization","","","","12","IEEE","16 Mar 2017","","","IEEE","IEEE Conferences"
"Using Software Metrics Thresholds to Predict Fault-Prone Classes in Object-Oriented Software","A. Boucher; M. Badri","Software Engineering Research Laboratory, University of Quebec, Trois-Rivières, Canada; Software Engineering Research Laboratory, University of Quebec, Trois-Rivières, Canada","2016 4th Intl Conf on Applied Computing and Information Technology/3rd Intl Conf on Computational Science/Intelligence and Applied Informatics/1st Intl Conf on Big Data, Cloud Computing, Data Science & Engineering (ACIT-CSII-BCD)","4 May 2017","2016","","","169","176","Most code-based quality measurement approaches are based, at least partially, on values of multiple source code metrics. A class will often be classified as being of poor quality if the values of its metrics are above given thresholds, which are different from one metric to another. The metrics thresholds are calculated using various techniques. In this paper, we investigated two specific techniques: ROC curves and Alves rankings. These techniques are supposed to give metrics thresholds which are practical for code quality measurements or even for fault-proneness prediction. However, Alves Rankings technique has not been validated as being a good choice for fault-proneness prediction, and ROC curves only partially on few datasets. Fault-proneness prediction is an important field of software engineering, as it can be used by developers and testers as a test effort indication to prioritize tests. This will allow a better allocation of resources, reducing therefore testing time and costs, and an improvement of the effectiveness of testing by testing more intensively the components that are likely more fault-prone. In this paper, we wanted to compare empirically the selected threshold calculation methods used as part of fault-proneness prediction techniques. We also used a machine learning technique (Bayes Network) as a baseline for comparison. Thresholds have been calculated for different object-oriented metrics using four different datasets obtained from the PROMISE Repository and another one based on the Eclipse project.","","978-1-5090-4871-7","10.1109/ACIT-CSII-BCD.2016.042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7916977","Metrics Thresholds;Class-Level Metrics;Object-Oriented Metrics;Faults;Fault-Proneness Prediction;Code Quality;Object-Oriented Programming","Measurement;Prediction algorithms;Testing;Context;Object oriented modeling;Java;Software","learning (artificial intelligence);object-oriented methods;program testing;software metrics;software quality;source code (software)","code-based quality measurement;source code metrics;ROC curves;Alves rankings;fault-proneness prediction;software engineering;test effort indication;machine learning;Bayes network;object-oriented metrics;PROMISE repository;Eclipse project","","8","","28","IEEE","4 May 2017","","","IEEE","IEEE Conferences"
"A Hybrid Algorithm for Multi-Objective Test Case Selection","T. Saber; F. Delavernhe; M. Papadakis; M. O'Neill; A. Ventresque","Natural Computing Research and Applications Group, University College Dublin, Ireland; School of Computer Science, University College Dublin, Ireland; Reliability and Trust, University of Luxembourg; Natural Computing Research and Applications Group, University College Dublin, Ireland; School of Computer Science, University College Dublin, Ireland","2018 IEEE Congress on Evolutionary Computation (CEC)","4 Oct 2018","2018","","","1","8","Testing is crucial to ensure the quality of software systems-but testing is an expensive process, so test managers try to minimise the set of tests to run to save computing resources and speed up the testing process and analysis. One problem is that there are different perspectives on what is a good test and it is usually not possible to compare these dimensions. This is a perfect example of a multi-objective optimisation problem, which is hard-especially given the scale of the search space here. In this paper, we propose a novel hybrid algorithm to address this problem. Our method is composed of three steps: a greedy algorithm to find quickly some good solutions, a genetic algorithm to increase the search space covered and a local search algorithm to refine the solutions. We demonstrate through a large scale empirical evaluation that our method is more reliable (better whatever the time budget) and more robust (better whatever the number of dimensions considered)-in the scenario with 4 objectives and a default execution time, we are 178% better in hypervolume on average than the state-of-the-art algorithms.","","978-1-5090-6017-7","10.1109/CEC.2018.8477875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477875","Multi-objective Optimisation;Hybrid-metaheuristic;Search-based Software Engineering;Test Suite Selection","Testing;Measurement;Evolutionary computation;Optimization;Greedy algorithms;Software;Software algorithms","genetic algorithms;greedy algorithms;program testing;search problems;software quality","genetic algorithm;search space;local search algorithm;multiobjective test case selection;test managers;testing process;multiobjective optimisation problem;greedy algorithm;software systems testing;hybrid algorithm;software system quality","","17","","31","IEEE","4 Oct 2018","","","IEEE","IEEE Conferences"
"Exploring the Presence of Technical Debt in Industrial GUI-Based Testware: A Case Study","E. Alégroth; M. Steiner; A. Martini","Department of Computer Science and Engineering, Chalmers University of Technology, Göteborg, Sweden; Department of Computer Science and Engineering, Chalmers University of Technology, Göteborg, Sweden; Department of Computer Science and Engineering, Chalmers University of Technology, Göteborg, Sweden","2016 IEEE Ninth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2016","2016","","","257","262","Technical debt (TD) is a concept used to describe a sub-optimal solution of a software artifact that negatively affects its comprehensibility, extendability and maintainability. As such, TD adversely affects the costs or quality associated with the artifact, which is also called interest. TD has through research been identified in all types of software artifacts, from architectural design to automated tests (Testware). However, research into testware technical debt (TTD) is limited and primarily focused on testing on lower level of system abstraction, i.e. unit-and integration tests, leaving a need for more TTD research on GUI-based testing. In this study we explore this gap in knowledge through an industrial case study at a Swedish avionics software development company. Four repositories are studied for the presence of TTD using expert interviews, semi-automated document analysis and automatic metric analysis. Results of the study provide initial support that the concept of TTD is applicable to GUI-based testware and show the presence of both TD items unique to GUI-based testware and items common to software. The implications of these results are that engineering best practices must be established for GUI-based testware to minimize TD interest.","","978-1-5090-3674-5","10.1109/ICSTW.2016.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528970","Technical debt;Testware;GUI-based testing;Industrial case study","Companies;Complexity theory;Testing;Software;Interviews;Measurement;Graphical user interfaces","graphical user interfaces;program testing;software architecture","industrial GUI-based testware;software artifact;architectural design;automated tests;testware technical debt;system abstraction;unit-and integration tests;GUI-based testing;Swedish avionics software development company;semi-automated document analysis;automatic metric analysis","","7","","24","IEEE","4 Aug 2016","","","IEEE","IEEE Conferences"
"Experience Report: How Effective is Automated Program Repair for Industrial Software?","K. Noda; Y. Nemoto; K. Hotta; H. Tanida; S. Kikuchi","FUJITSU LABORATORIES LTD., Japan; FUJITSU LABORATORIES LTD., Japan; FUJITSU LABORATORIES LTD., Japan; FUJITSU LABORATORIES LTD., Japan; FUJITSU LABORATORIES LTD., Japan","2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)","2 Apr 2020","2020","","","612","616","Recent advances in automated program repair (APR) have widely caught the attention of industrial developers as a way of reducing debugging costs. While hundreds of studies have evaluated the effectiveness of APR on open-source software, industrial case studies on APR have been rarely reported; it is still unclear whether APR can work well for industrial software. This paper reports our experience applying a state-of-the-art APR technique, ELIXIR, to large industrial software consisting of 150+ Java projects and 13 years of development histories. It provides lessons learned and recommendations regarding obstacles to the industrial use of current APR: low recall (7.7%), lack of bug-exposing tests (90%), low success rate (10%), among others. We also report the preliminary results of our ongoing improvement of ELIXIR. With some simple enhancements, the success rate of repair has been greatly improved by up to 40%.","1534-5351","978-1-7281-5143-4","10.1109/SANER48275.2020.9054829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054829","automated program repair;industrial experience report;practical performance","Java;Costs;Conferences;Computer bugs;Debugging;Maintenance engineering;History","Java;program debugging;program diagnostics;program testing;public domain software;software cost estimation;software maintenance","automated program repair;industrial software;industrial developers;open-source software;industrial case studies;APR;ELIXIR;debugging cost reduction;Java projects","","3","","21","IEEE","2 Apr 2020","","","IEEE","IEEE Conferences"
"Search-Based Test Data Generation for SQL Queries","J. Castelein; M. Aniche; M. Soltani; A. Panichella; A. van Deursen",NA; NA; NA; NA; NA,"2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","2 Sep 2018","2018","","","1220","1230","Database-centric systems strongly rely on SQL queries to manage and manipulate their data. These SQL commands can range from very simple selections to queries that involve several tables, subqueries, and grouping operations. And, as with any important piece of code, developers should properly test SQL queries. In order to completely test a SQL query, developers need to create test data that exercise all possible coverage targets in a query, e.g., JOINs and WHERE predicates. And indeed, this task can be challenging and time-consuming for complex queries. Previous studies have modeled the problem of generating test data as a constraint satisfaction problem and, with the help of SAT solvers, generate the required data. However, such approaches have strong limitations, such as partial support for queries with JOINs, subqueries, and strings (which are commonly used in SQL queries). In this paper, we model test data generation for SQL queries as a search-based problem. Then, we devise and evaluate three different approaches based on random search, biased random search, and genetic algorithms (GAs). The GA, in particular, uses a fitness function based on information extracted from the physical query plan of a database engine as search guidance. We then evaluate each approach in 2,135 queries extracted from three open source software and one industrial software system. Our results show that GA is able to completely cover 98.6% of all queries in the dataset, requiring only a few seconds per query. Moreover, it does not suffer from the limitations affecting state-of-the art techniques.","1558-1225","978-1-4503-5638-1","10.1145/3180155.3180202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453204","search based software engineering;automated test data generation;SQL;databases","Databases;Genetic algorithms;Search problems;Structured Query Language;Toy manufacturing industry;Software systems;Engines","database management systems;genetic algorithms;program testing;query processing;search problems;SQL","SQL query;complex queries;model test data generation;physical query plan;Search-Based Test Data Generation;database-centric systems;SQL queries;SQL commands;constraint satisfaction problem;search-based problem;biased random search;genetic algorithms;database engine;search guidance;open source software;industrial software system","","7","","","","2 Sep 2018","","","IEEE","IEEE Conferences"
"Dynamic Random Testing: Technique and Experimental Evaluation","H. Pei; K. -Y. Cai; B. Yin; A. P. Mathur; M. Xie","Department of Automatic Control, Beihang University, Beijing, China; Department of Automatic Control, Beihang University, Beijing, China; Department of Automatic Control, Beihang University, Beijing, China; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Systems Engineering and Engineering Management, City University of Hong Kong, Hong Kong","IEEE Transactions on Reliability","30 Aug 2019","2019","68","3","872","892","A particularly good software testing strategy is to achieve the underlying testing goal while solving the problems of tradeoffs between testing effectiveness and efficiency. To improve the fault detection effectiveness of software testing, the principle of feedback control theory was adopted, which motivated the proposal of dynamic random testing (DRT). The main idea behind DRT is using the testing results to guide the test case selection to increase the selection probabilities of the subdomains with higher fault detection rates. Previous works show that DRT strategy can achieve better effectiveness than random testing strategy and random partition testing strategy, and has significantly lower computational costs than adaptive testing strategy. However, the essential factors that affect the performance of DRT, i.e., adjusting parameters, initial profile, and test case classification have not been thoroughly investigated. Besides, some experimental assumptions are inconsistent with real scenarios. Therefore, this paper gives a series of investigations on DRT with a set of practical subject programs. More specifically, the effectiveness and efficiency of DRT are presented, and the extended experiments on DRT with relevant factors are conducted. The results indicate that the effectiveness of DRT is robust to different initial profiles and affected noticeably by the adjusting parameter settings and test case classification methods.","1558-1721","","10.1109/TR.2019.2911593","National Natural Science Foundation of China(grant numbers:61402027); National Natural Science Foundation of China(grant numbers:61772055); Equipment preresearch projects(grant numbers:41402020102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721158","Dynamic random testing (DRT);random partition testing (RPT);software cybernetics;testing profiles","Fault detection;Software testing;Feedback;Computational efficiency;Probability","feedback;probability;program testing","dynamic random testing;test case selection;DRT strategy;random partition testing strategy;adaptive testing strategy;test case classification methods;software testing strategy;fault detection","","6","","48","IEEE","23 May 2019","","","IEEE","IEEE Journals"
"Improving mutant generation for Simulink models using genetic algorithm","N. T. H. Quyen; K. T. Tung; L. T. M. Hanh; N. T. Binh","Danang College of Technology, Danang, Vietnam; DATIC Laboratory, Danang University of Science and Technology, Danang, Vietnam; DATIC Laboratory, Danang University of Science and Technology, Danang, Vietnam; DATIC Laboratory, Danang University of Science and Technology, Danang, Vietnam","2016 International Conference on Electronics, Information, and Communications (ICEIC)","8 Sep 2016","2016","","","1","4","Simulink is one of the most popular tools used to design dynamic models for industrial complex systems. Mutation testing is a fault-based technique widely used for testing software. However, the testing cost is often very high. A tool which allows automatic testing for Simulink models with only a subset of mutants to reduce testing costs and time while ensuring the quality of software products is very neccessary. This paper proposes the use of genetic algorithm to minimize the number of generated mutants without losing the efficiency of mutation testing approach. The experiment confirms that the proposed method contributed to the reduction in time and costs for mutation testing process.","","978-1-4673-8016-4","10.1109/ELINFOCOM.2016.7562970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562970","mutation testing;mutant;genetic algorithm;Simulink model;fitness function","Software packages;Testing;Genetic algorithms;Sociology;Statistics;Analytical models;Syntactics","genetic algorithms;minimisation;program testing;software quality","mutant generation improvement;Simulink models;genetic algorithm;mutation testing;fault-based technique;automatic testing;testing cost reduction;time reduction;software product quality","","4","","9","IEEE","8 Sep 2016","","","IEEE","IEEE Conferences"
"KORAT — A platform independent test automation tool by emulating keyboard/mouse hardware signals","Y. -P. Cheng; D. Liang; W. -J. Wang","Software Center, National Central University, Zhongli, TAIWAN; Software Center, National Central University, Zhongli, TAIWAN; Software Center, National Central University, Zhongli, TAIWAN","2016 IEEE AUTOTESTCON","13 Oct 2016","2016","","","1","7","Software, ranging from firmware, BIOS, and embedded software to complex software products, can only be tested by designing test cases to go through code and then verifying the results with expected outcomes. When code is changed frequently, regression testing is critical to ensure that changes do not introduce new faults. However, depending on the input types of the system under test (SUT), regression tests often require testers to drive the SUT manually, mainly by keyboard and mouse. In the meantime, testers play an important role as test oracle to determine the correctness of a test run by observing if the SUT behaves abnormally. Regression tests can be automated by programming or adopting testing tools. The most cost-effective approach supported by some commercial testing tools is capturing the testing behaviors of a human tester and then replaying the tests to assert the correctness. Unfortunately, most capture/replay tools are designed for testing the software which must be executed under a general-purpose O.S. They are inapplicable to many software systems, such as embedded software, BIOS, etc. In this paper, a capture/replay testing tool called KORAT is proposed. KORAT adopts a hardware component to intercept and emulate keyboard/mouse signals to drive an SUT as if the SUT is interacting with a human. A tester can design and operate a test case on a correct SUT to record the behaviors into a KORAT test script, in which no programming skills are required. In a regression run, the test case is replayed and the correctness is asserted automatically by analyzing SUT's video output (aka, images) and sending keyboard and mouse signals smartly. The correctness of a replay run can be asserted by image recognition, optical character recognition (OCR), and ASCII string matching via networking. Since KORAT only interfaces the video output of a SUT, it is platform independent and non-intrusive; meaning there is no performance interference caused by KORAT's capture and replay. A real application of KORAT to BIOS regression testing of industrial computer (militarized computers) manufacturing is described.","1558-4550","978-1-5090-0790-5","10.1109/AUTEST.2016.7589572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589572","","Testing;Software;Mice;Automation;Keyboards;Programming;Interference","automatic test software;keyboards;mouse controllers (computers);program testing","platform independent test automation tool;keyboard hardware signals;mouse hardware signals;software testing;automated regression testing;system under test;SUT video output analysis;test oracle;test correctness;programming tools;testing tools;software systems;capture replay testing tool;hardware component interception;KORAT test script;image recognition;optical character recognition;OCR;ASCII string matching;BIOS regression testing;industrial computer manufacturing;militarized computers","","1","","11","IEEE","13 Oct 2016","","","IEEE","IEEE Conferences"
"Defect Prediction on a Legacy Industrial Software: A Case Study on Software with Few Defects","Y. Koroglu; A. Sen; D. Kutluay; A. Bayraktar; Y. Tosun; M. Cinar; H. Kaya","Department of Computer Engineering, Bogazici University, Istanbul, Turkey; Department of Computer Engineering, Bogazici University, Istanbul, Turkey; Netas Telecommunications, Istanbul, Turkey; Netas Telecommunications, Istanbul, Turkey; Netas Telecommunications, Istanbul, Turkey; Netas Telecommunications, Istanbul, Turkey; Netas Telecommunications, Istanbul, Turkey","2016 IEEE/ACM 4th International Workshop on Conducting Empirical Studies in Industry (CESI)","9 Jan 2017","2016","","","14","20","Context: Building defect prediction models for software projects is helpful for reducing the effort in locating defects. In this paper, we share our experiences in building a defect prediction model for a large industrial software project. We extract product and process metrics to build models and show that we can build an accurate defect prediction model even when 4% of the software is defective. Objective: Our goal in this project is to integrate a defect predictor into the continuous integration (CI) cycle of a large software project and decrease the effort in testing. Method: We present our approach in the form of an experi- ence report. Specifically, we collected data from seven older versions of the software project and used additional features to predict defects of current versions. We compared several classification techniques including Naive Bayes, Decision Trees, and Random Forest and resampled our training data to present the company with the most accurate defect predictor. Results: Our results indicate that we can focus testing ef- forts by guiding the test team to only 8% of the software where 53% of actual defects can be found. Our model has 90% accuracy. Conclusion: We produce a defect prediction model with high accuracy for a software with defect rate of 4%. Our model uses Random Forest, that which we show has more predictive power than Naive Bayes, Logistic Regression and Decision Trees in our case.","","978-1-4503-4154-7","10.1145/2896839.2896843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809362","Defect Prediction;Experience Report;Process Metrics;Feature Selection;Random Forest","Measurement;Software;Predictive models;Companies;Computer bugs;Java;Testing","Bayes methods;decision trees;learning (artificial intelligence);pattern classification;program testing;project management;software maintenance;software management;software metrics","legacy industrial software;software defect prediction;large industrial software project;process metrics;continuous integration cycle;software testing;classification techniques;Naive Bayes;decision trees;random forest;training data","","2","","21","","9 Jan 2017","","","IEEE","IEEE Conferences"
"COMPI: Concolic Testing for MPI Applications","H. Li; S. Li; Z. Benavides; Z. Chen; R. Gupta","Department of Computer Science and Engineering, University of California, Riverside Riverside, USA; Department of Computer Science and Engineering, University of California, Riverside Riverside, USA; Department of Computer Science and Engineering, University of California, Riverside Riverside, USA; Department of Computer Science and Engineering, University of California, Riverside Riverside, USA; Department of Computer Science and Engineering, University of California, Riverside Riverside, USA","2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","6 Aug 2018","2018","","","865","874","MPI is widely used as the bedrock of HPC applications, but there are no effective systematic software testing techniques for MPI programs. In this paper we develop COMPI, the first practical concolic testing tool for MPI applications. COMPI tackles two major challenges. First, it provides an automated testing tool for MPI programs - it performs concolic execution on a single process and records branch coverage across all. Infusing MPI semantics such as MPI rank and MPI_COMM_WORLD into COMPI enables it to automatically direct testing with various processes' executions as well as automatically determine the total number of processes used in the testing. Second, COMPI employs three techniques to effectively control the cost of testing as too high a cost may prevent its adoption. By capping input values, COMPI is made practical as too large an input can make the testing extremely slow and sometimes even fail as memory needed could exceed the computing platform's memory limit. With two-way instrumentation, we reduce the unnecessary memory and I/O overhead of COMPI and the target program. With constraint set reduction, COMPI keeps significantly fewer constraints by removing redundant ones in the presence of loops so as to avoid redundant tests against these branches. Our evaluation of COMPI uncovered four new bugs in a complex application and achieved 69-86% branch coverage which far exceeds the 1.8-38% coverage achieved via random testing.","1530-2075","978-1-5386-4368-6","10.1109/IPDPS.2018.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425240","MPI;Concolic Testing;Practical","Testing;Instruments;Computer bugs;Semantics;Tools;Standards;Force","application program interfaces;message passing;parallel processing;program diagnostics;program testing;software fault tolerance","COMPI;MPI applications;MPI programs;practical concolic testing tool;automated testing tool;infusing MPI semantics;MPI rank;MPI_COMM_WORLD;automatically direct testing;redundant tests;random testing;IO overhead;effective systematic software testing techniques","","5","","39","IEEE","6 Aug 2018","","","IEEE","IEEE Conferences"
"Petri net based software testing scheduling and selecting","Senke Ding; Peifu Xu; W. Wu; Yi Yang; Zichao Xing; Feihua Lu; Cheng Li","Institute of Cyber-systems and Control, Zhejiang University, Hangzhou, China; China Tobacco, Zhejiang Industrial Co., Ltd, Hangzhou, China; Institute of Cyber-systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-systems and Control, Zhejiang University, Hangzhou, China","2017 IEEE 14th International Conference on Networking, Sensing and Control (ICNSC)","3 Aug 2017","2017","","","168","173","Computer software system has a profound impact on human society. It increasingly highlights the importance of software testing. Reducing the cost and improving the efficiency of software testing has an important practical significance and economic value. This paper investigates on software testing workflow from the perspective of discrete event dynamic systems and presents a method to improve the efficiency of software testing by optimizing task scheduling and execution priorities. We developed a simulation program of task scheduling based on Petri net to compare the performance of each scheduling option in different situations and made the analysis of their differences.","","978-1-5090-4429-0","10.1109/ICNSC.2017.8000086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8000086","","Software;Analytical models;Phase locked loops","discrete event systems;Petri nets;program testing;scheduling","Petri net based software testing scheduling;computer software system;discrete event dynamic systems;task scheduling;execution priorities","","","","8","IEEE","3 Aug 2017","","","IEEE","IEEE Conferences"
"Software Reliability Modeling and Analysis via Kernel-Based Approach","K. Okumura; H. Okamura; T. Dohi","Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, Japan","2017 22nd International Conference on Engineering of Complex Computer Systems (ICECCS)","15 Feb 2018","2017","","","154","157","Traditional software reliability analysis utilizes only the fault count data observed in testing phase, and is done independently of the source code itself. Recently, it is known that utilization of software metrics in software reliability modeling and analysis can lead to more accurate reliability estimation and fault prediction through many empirical studies. However, such a metrics-based modeling also requires a careful selection of software metrics and their measurement, which are often troublesome and cost-consuming in practice. In this paper, we propose a kernel-based approach to estimate the quantitative software reliability, where two cases are considered; multiple software metrics are used and not. In the former case, we combine the kernel regression with the well-known non-homogeneous Poisson process-based software reliability growth model (SRGM), and propose a new metrics-based SRGM. In the latter case, we perform a similarity-based analysis through a source code transformation algorithm and try to estimate the quantitative software reliability from the source code directly without measuring multiple software metrics. Numerical examples with real application programs are presented to validate our kernel-based approach in the above two cases.","","978-1-5386-2431-9","10.1109/ICECCS.2017.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8292815","software reliability;software reliability growth model;kernel method;non-homogeneous Poisson process;similarity analysis;static source code analysis;statistical estimation;regularization;fault-free probability","Kernel;Software reliability;Software metrics;Estimation","program testing;regression analysis;software fault tolerance;software metrics;source code (software);stochastic processes","fault count data;software reliability modeling;fault prediction;quantitative software reliability;software reliability growth model;source code transformation algorithm;software reliability analysis;reliability estimation;software metrics;kernel-based approach;SRGM;kernel regression;nonhomogeneous Poisson process;testing phase;similarity-based analysis","","","","7","IEEE","15 Feb 2018","","","IEEE","IEEE Conferences"
"Simultaneous Refactoring and Regression Testing","J. J. Yackley; M. Kessentini; G. Bavota; V. Alizadeh; B. R. Maxim","CIS Department, University of Michigan, Dearborn, Michigan, USA; CIS Department, University of Michigan, Dearborn, Michigan, USA; Faculty of Informatics, Universit?? della Svizzera italiana, Lugano, Switzerland; CIS Department, University of Michigan, Dearborn, Michigan, USA; CIS Department, University of Michigan, Dearborn, Michigan, USA","2019 19th International Working Conference on Source Code Analysis and Manipulation (SCAM)","12 Dec 2019","2019","","","216","227","Currently, refactoring and regression testing are treated independently by existing studies. However, software developers frequently switch between these two activities, using regression testing to identify unwanted behavior changes introduced while refactoring and applying refactoring on identified buggy code fragments. Our hypothesis is that the tools to support developers in these two tasks could transfer part of the knowledge extracted from the process of finding refactoring opportunities to identify relevant test cases, and vice-versa. We propose a simultasking, search-based algorithm that unifies the tasks of refactoring and regression testing, hence solving them simultaneously and enabling knowledge transfer between them. The salient feature of the proposed algorithm is a unified and generic solution representation scheme for both problems, which serves as a common platform for knowledge transfer between them. We implemented and evaluated the proposed simultasking approach on six opensource systems and one industrial project. Our study features quantitative and qualitative analysis performed with developers, and the results achieved show that the proposed approach provides advantages over mono-task techniques treating refactoring and regression testing separately.","2470-6892","978-1-7281-4937-0","10.1109/SCAM.2019.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930845","Refactoring, regression testing, search based software engineering","Testing;Task analysis;Computer bugs;Knowledge transfer;Sociology;Statistics;Genetics","object-oriented methods;program testing;public domain software;regression analysis;search problems;software maintenance;software metrics","refactoring opportunities;relevant test cases;regression testing;knowledge transfer;simultaneous refactoring;refactoring applying;identified buggy code fragments;simultasking algorithm;search-based algorithm;salient feature;generic solution representation scheme;mono-task techniques","","","","45","IEEE","12 Dec 2019","","","IEEE","IEEE Conferences"
"Continuous Integration, Delivery and Deployment: A Systematic Review on Approaches, Tools, Challenges and Practices","M. Shahin; M. Ali Babar; L. Zhu","Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, SA, Australia; Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, SA, Australia; Data61, Commonwealth Scientific and Industrial Research Organisation, Sydney, NSW, Australia","IEEE Access","20 May 2017","2017","5","","3909","3943","Continuous practices, i.e., continuous integration, delivery, and deployment, are the software development industry practices that enable organizations to frequently and reliably release new features and products. With the increasing interest in the literature on continuous practices, it is important to systematically review and synthesize the approaches, tools, challenges, and practices reported for adopting and implementing continuous practices. This paper aimed at systematically reviewing the state of the art of continuous practices to classify approaches and tools, identify challenges and practices in this regard, and identify the gaps for future research. We used the systematic literature review method for reviewing the peer-reviewed papers on continuous practices published between 2004 and June 1, 2016. We applied the thematic analysis method for analyzing the data extracted from reviewing 69 papers selected using predefined criteria. We have identified 30 approaches and associated tools, which facilitate the implementation of continuous practices in the following ways: (1) reducing build and test time in continuous integration (CI); (2) increasing visibility and awareness on build and test results in CI; (3) supporting (semi-) automated continuous testing; (4) detecting violations, flaws, and faults in CI; (5) addressing security and scalability issues in deployment pipeline; and (6) improving dependability and reliability of deployment process. We have also determined a list of critical factors, such as testing (effort and time), team awareness and transparency, good design principles, customer, highly skilled and motivated team, application domain, and appropriate infrastructure that should be carefully considered when introducing continuous practices in a given organization. The majority of the reviewed papers were validation (34.7%) and evaluation (36.2%) research types. This paper also reveals that continuous practices have been successfully applied to both greenfield and maintenance projects. Continuous practices have become an important area of software engineering research and practice. While the reported approaches, tools, and practices are addressing a wide range of challenges, there are several challenges and gaps, which require future research work for improving the capturing and reporting of contextual information in the studies reporting different aspects of continuous practices; gaining a deep understanding of how software-intensive systems should be (re-) architected to support continuous practices; and addressing the lack of knowledge and tools for engineering processes of designing and running secure deployment pipelines.","2169-3536","","10.1109/ACCESS.2017.2685629","Data61, a business unit of CSIRO, Australia; Australian Government Research Training Program Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884954","Continuous integration;continuous delivery;continuous deployment;continuous software engineering;systematic literature review;empirical software engineering","Software;Organizations;Software engineering;Systematics;Bibliographies;Testing;Production","program testing;software fault tolerance;software houses;software maintenance","software engineering;software-intensive systems;maintenance projects;greenfield projects;design principles;transparency;team awareness;critical factors;deployment process dependability improvement;deployment process reliability improvement;scalability issues;security issues;fault detection;flaw detection;violation detection;semiautomated continuous testing;CI;test time reduction;build time reduction;thematic analysis method;continuous practices;systematic literature review method;software development industry practices;software deployment;software delivery;continuous integration","","223","","59","OAPA","22 Mar 2017","","","IEEE","IEEE Journals"
"Comparing the effort and effectiveness of automated and manual tests","I. Dobles; A. Martínez; C. Quesada-López","Universidad de Costa Rica, San Jose, San JosÃ©, CR; Universidad de Costa Rica, San Jose, San JosÃ©, CR; Universidad de Costa Rica, San Jose, San JosÃ©, CR","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","6","This paper presents three case studies that compare the effort and effectiveness of automated versus manual testing, in the context of a multinational services organization. Effort is measured in terms of the total test time, which includes script creation and test execution in the case of automated testing, and comprises test execution and reporting in the case of manual testing. Effectiveness is measured in terms of the number and severity of defects found. The software under test is a set of Java web applications. The testing process was carried out by two testers within the organization. Our results show that automated testing needs a higher initial effort, mainly caused by the creation of the scripts, but this cost can be amortized in time as automated tests are executed multiple times for regression testing. Results also show that automated testing is more effective than manual testing at finding defects.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760848","automated testing;manual testing;effectiveness;effort;industrial case study","Manuals;Testing;Automation;Tools;Organizations;Software;Investment","Java;program testing","manual testing;total test time;test execution;automated testing;regression testing;multinational service organization;script creation;Java Web applications","","1","","14","","15 Jul 2019","","","IEEE","IEEE Conferences"
"A Hybrid Nonlinear Manifold Detection Approach for Software Defect Prediction","S. Ghosh; A. Rana; V. Kansal","Department of Computer Science & Engineering, Amity University Uttar Pradesh Noida, Uttar Pradesh, India; Department of Computer Science & Engineering, Amity University Uttar Pradesh Noida, Uttar Pradesh, India; Department of Computer Science & Engineering, Institute of Engineering and Technology Lucknow, India","2018 7th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","1 Jul 2019","2018","","","453","459","Rapid development of software technology has influence on substantial industrial growth. Wide application of software in business related matters leads to development of reliable and defect free software system which is a challenging task. It requires development of effective techniques for prediction of software defects at early stage. For complexities in manual prediction of defects, automated techniques have come into effect. They are basically based on learning of pattern from earlier versions of software development and finding out the defects from the current version. Considerable impact of these techniques on industrial growth by predicting defects in software system attracted researchers in this field.In-spite of many studies performed by applying these techniques, desirable performance level and accurate defect prediction still remains a challenging task. For solving this problem, a hybrid technique based on Nonlinear Manifold Detection Techniques (Nonlinear MDTs) and machine learning for prediction of defects has been proposed in this paper. A new hybrid Nonlinear Manifold Detection (Nonlinear MD) Model has been applied for selecting and optimizing the features of software datasets that have been processed using Decision Tree (DT) and Random Forest (RF) classifications. Finally, a comparison and statistical evaluation of the experimental results obtained using new hybrid Nonlinear MD Model-DT have been made by Friedman test followed by Wilcoxon Sign rank test. The statistical outcome revealed that the proposed new hybrid Nonlinear MD Model-DT classification is better result oriented and more accurate in software defect prediction.","","978-1-5386-4692-2","10.1109/ICRITO.2018.8748788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8748788","Decision Tree;Dimensionality Reduction;Feature Optimization;Friedman test;Nonlinear Manifold Detection;Software Defect Prediction;Wilcoxon sign rank test","Software;Optimization;Manifolds;Machine learning;Predictive models;Feature extraction;Data mining","decision trees;feature selection;pattern classification;program testing;random forests;software metrics;software quality;software reliability;statistical analysis","software defect prediction;software technology;substantial industrial growth;automated techniques;software development;machine learning;hybrid nonlinear MD model-DT classification;nonlinear MDTs;hybrid nonlinear manifold detection approach;nonlinear manifold detection techniques;features selection;features optimization;decision tree;random forest classifications;RF classifications;statistical evaluation;Friedman test;Wilcoxon Sign rank test;defect free software system;reliable free software system","","6","","27","IEEE","1 Jul 2019","","","IEEE","IEEE Conferences"
"A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques","R. Gao; Z. M. Jiang; C. Barna; M. Litoiu","Department of Electrical Engineering and Computer Science, York University, Toronto, Canada; York University, Toronto, ON, CA; Department of Electrical Engineering and Computer Science, York University, Toronto, Canada; School of Information Technology, York University, Toronto, Canada","2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)","21 Jul 2016","2016","","","22","32","Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (≥ 180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download.","","978-1-5090-1827-7","10.1109/ICST.2016.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515456","","Testing;Radiation detectors;Data models;Load modeling;Data mining;Queueing analysis;Topology","control charts;large-scale systems;program testing;public domain software;regression analysis;statistics;trees (mathematics)","load testing analysis;large-scale software systems;Amazon;eBay;open source systems;control chart;descriptive statistics;regression tree","","11","","45","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"Model for teaching and training software testing in an agile context","I. S. Elgrably; S. Ronaldo Bezerra Oliveira","Graduate Program in Computer Sciense (PPGCC), Institute of Exact and Natural Sciences (ICEN), Federal University of Pará (UFPA), Belém, PA, Brazil; Graduate Program in Computer Sciense (PPGCC), Institute of Exact and Natural Sciences (ICEN), Federal University of Pará (UFPA), Belém, PA, Brazil","2020 IEEE Frontiers in Education Conference (FIE)","4 Dec 2020","2020","","","1","9","This Research to Practice Full Paper presents a proposal for a model to improve the teaching process of software testing supported by elements of agile methods. It was developed to be used as a guide to support professors or specialists for decision making, selection of teaching materials according to the participants' cognitive learning for the execution of subjects or teaching units on topics related to software testing. In addition to suggesting several personalized activities, presenting an instance of application of a teaching syllabus that adheres to several reference syllabus, this model also seeks to be extensible, to be applied in other teaching areas, trying not to be limited to the software testing area. The construction of this model makes use of practical teaching approaches supported by practices, such as gamification and playful teaching to motivate and engage participants, bringing common tasks and technologies in the software industry in parallel to classic lecture classes, in order to develop certain skills, which were obtained through academic syllabus, together with technical skills in software testing for participants, in addition to knowledge of several open source tools that are used by testing professionals in the software industry. This construction is specified in several stages arranged in a teaching cycle, being sequenced when they are applied and can be adapted for other learning scenarios. Subsequently, the skills, competences and support materials that can be used are presented in addition to the possible effects expected on students from the application of this model in the teaching of software testing. As it uses practical teaching approaches, it is advisable that this model is used by professors who have a teaching facilitator profile, as it presents humanistic teaching learning, with a focus on participants and teamwork, principles found in agile methods, in which activities will have deliveries of products that approach what is performed in a software company and it will be necessary the interaction of all participants in the model. The evaluation process for this teaching model took place in two stages. First, there was an analysis and individual evaluation of the model through the questionnaire, then there was a consensus meeting between the evaluators, where they justified the marks attributed in the evaluation and their considerations on other responses. This meeting aimed to solve disagreements and collect opinions, enabling problems to be solved and reaching a final consensus among the evaluators. The authors consider that it is necessary to remodel teaching paradigms of computing subjects, using together some characteristics of traditional approaches with more practical teaching approaches that solidify the knowledge of the participants for the challenges that exist in the software industry.","2377-634X","978-1-7281-8961-1","10.1109/FIE44824.2020.9274117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274117","software testing;teaching model;focus on student;technical skills","Education;Software testing;Software;Computational modeling;Industries;Training;Task analysis","computer aided instruction;computer science education;decision making;educational courses;program testing;teaching","training software testing;teaching process;agile methods;teaching materials;teaching units;teaching syllabus;teaching areas;software testing area;practical teaching approaches;playful teaching;software industry;teaching cycle;support materials;teaching facilitator profile;humanistic teaching learning;teaching model;teaching paradigms","","5","","30","IEEE","4 Dec 2020","","","IEEE","IEEE Conferences"
"Supporting Coordination in Crowdsourced Software Testing Services","M. Alsayyari; S. Alyahya","Information Systems Department, King Saud University, Riyadh, Saudi Arabia; Information Systems Department, King Saud University, Riyadh, Saudi Arabia","2018 IEEE Symposium on Service-Oriented System Engineering (SOSE)","17 May 2018","2018","","","69","75","Crowdsourcing is a new phenomenon with great opportunities and benefits; it refers to outsourcing a task to the internet crowds. Crowdsourced Software Testing (CST) is a specific, valuable crowdsourcing service. Its scale, flexibility, cost effectiveness and fast turnaround times are just a few reasons why web-based crowdsourced testing services have recently received a great deal of attention. Major software companies have used CST to test their applications. However, CST has its own challenges and limitations (e.g., tester selection dilemmas, test report processing, overall test quality). The lack of coordination support in CST activities is causing delays and missed opportunities; hence, the best test results may not be guaranteed. This paper presents ongoing research that aims to support coordination in CST activities by identifying coordination challenges in the current practices. The quantitative comparison of 15 CST platforms reveals a lack of computer-based support for testers, project managers and clients.","","978-1-5386-5207-7","10.1109/SOSE.2018.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359151","Crowdsourcing;Software Testing;Crowdsourced Software Testing;Coordination;Process improvements;Web Services.","Computer bugs;Software testing;Crowdsourcing;Software;Outsourcing;Task analysis","crowdsourcing;Internet;program testing","turnaround times;software companies;tester selection dilemmas;test report processing;test quality;crowdsourced software testing services;internet crowds;CST;outsourcing task;CST platforms;Web-based crowdsourced testing services","","8","","21","Crown","17 May 2018","","","IEEE","IEEE Conferences"
"Automation of regression test in microservice architecture","M. J. Kargar; A. Hanifizade","Department of Computer Engineering, University of science and Culture, Tehran, Iran; Department of Computer Engineering, University of science and Culture, Tehran, Iran","2018 4th International Conference on Web Research (ICWR)","18 Jun 2018","2018","","","133","137","Nowadays Microservice, as one of the most important architectural approaches towards Cloud Computing, has caught the attention of many developers. To give a simple definition of microservice, it could be said: Each microservice is completely independent, and implements a part of the business, which is composed of several microservices. Each microservice could be deployed, updated, and scaled, without any impact on other microservices, and it is all automated. Among Agile methods, Continuous Delivery has played an important role in development process of Microservice-based systems. Continuous Delivery provides faster delivery of changes and faster getting customer's feedbacks. Continuous Delivery consists of many sections, one of which is Software Test. One of the challenges of automated deploying of new releases to production environment, is software reliability, that in case it is breached, the beneficiaries would suffer considerable losses. Regression test is one of the tests used for ensuring reliability, which compares two system versions based on various metrics. This paper proposes an automated method in running this test, which places Regression test in Continuous Delivery steps, which tests operability of the last developed version as a black box, and prevents writing test unit. Finally, microservice developers could ensure the operability of the developed microservice dependencies through investigating obtained comparisons.","","978-1-5386-5364-7","10.1109/ICWR.2018.8387249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387249","microservice;regression test;continuous delivery;DevOps","Computer architecture;Production;Software;Tools;Java;Software reliability;Measurement","cloud computing;program testing;regression analysis;software reliability","regression test;microservice architecture;Continuous Delivery;Cloud Computing;Agile methods;microservice dependencies;Software Test;software reliability","","5","","10","IEEE","18 Jun 2018","","","IEEE","IEEE Conferences"
"Framework for Flexible, Adaptive Support of Test Management by Means of Software Agents","C. V. Jordan; F. Mäurer; S. Löwenberg; J. Provost","Technical University of Munich, Munich, Germany; Technical University of Munich, Munich, Germany; TraceTronic GmbH, Dresden, Germany; Technical University of Munich, Munich, Germany","IEEE Robotics and Automation Letters","4 Jun 2019","2019","4","3","2754","2761","In the context of system testing on hardware-in-theloop test benches, performing functional tests on electrical control units comes with various challenges. Especially planning the execution of test cases for a test cycle and nightly batch runs is cumbersome. In order to support the test managers, this letter proposes an adaptable and flexible test management assistance system. Therefore, a set of requirements for such an assistance system has been identified and proposed solutions from the literature have been recalled. Out of those, software agents appear to be a suitable method for building up the framework of the assistance system. The framework proposed in this letter is divided into two phases: static prioritization of test scripts and dynamic execution ordering. The agents of the former phase aggregate relevant available data from various sources to calculate a test script priority. In the latter, the agents negotiate to solve the resource allocation problem for test scripts on test benches. In addition, test logs are taken into account at runtime for reprioritization. Finally, an industrial use case from the automotive industry is taken as an example to discuss the applicability and current obstacles on the way to application and qualitative evaluation of the expected benefits are discussed.","2377-3766","","10.1109/LRA.2019.2918486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719978","Agent-based systems;planning;scheduling and coordination;task planning","Software agents;Job shop scheduling;Planning;Adaptive systems;System testing;Automotive engineering","multi-agent systems;program testing;resource allocation;software agents","phase aggregate relevant available data;dynamic execution ordering;flexible test management assistance system;adaptable test management assistance system;test managers;test cycle;test cases;electrical control units;functional tests;hardware-in-theloop test benches;system testing;software agents;adaptive support;flexible support;test logs;test scripts;test script priority","","2","","23","IEEE","22 May 2019","","","IEEE","IEEE Journals"
"Development Flow for On-Line Core Self-Test of Automotive Microcontrollers","P. Bernardi; R. Cantoro; S. De Luca; E. Sánchez; A. Sansonetti","Politecnico di Torino, Dipartimento di Automatica e Informatica, Torino, Italy; Politecnico di Torino, Dipartimento di Automatica e Informatica, Torino, Italy; STMicroelectronics, Agrate Brianza, Italy; Politecnico di Torino, Dipartimento di Automatica e Informatica, Torino, Italy; STMicroelectronics, Agrate Brianza, Italy","IEEE Transactions on Computers","8 Feb 2016","2016","65","3","744","754","Software-Based Self-Test is an effective methodology for devising the online testing of Systems-on-Chip. In the automotive field, a set of test programs to be run during mission mode is also called Core Self-Test library. This paper introduces many new contributions: (1) it illustrates the several issues that need to be taken into account when generating test programs for on-line execution; (2) it proposed an overall development flow based on ordered generation of test programs that is minimizing the computational efforts; (3) it is providing guidelines for allowing the coexistence of the Core Self-Test library with the mission application while guaranteeing execution robustness. The proposed methodology has been experimented on a large industrial case study. The coverage level reached after one year of team work is over 87 percent of stuck-at fault coverage, and execution time is compliant with the ISO26262 specification. Experimental results suggest that alternative approaches may request excessive evaluation time thus making the generation flow unfeasible for large designs.","1557-9956","","10.1109/TC.2015.2498546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321794","Microprocessors and microcomputers;Reliability and Testing;Software-Based Self-Test;Microprocessors and microcomputers;reliability and testing;software-based self-test","Built-in self-test;Registers;Automotive engineering;Robustness;Standards;Interrupters","automobile industry;automotive electronics;fault diagnosis;ISO standards;microcontrollers;program testing;system-on-chip","development flow;on-line core self-test;automotive microcontroller;software-based self-test;systems-on-chip;test program generation;stuck-at fault coverage;ISO26262 specification;automotive industry","","54","1","30","IEEE","6 Nov 2015","","","IEEE","IEEE Journals"
"Supporting efficient test automation using lightweight MBT","E. Bernard; F. Ambert; B. Legeard","FEMTO-ST Institute, Univ. Bourgogne Franche-Comté, CNRS, Besancon, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comté, CNRS, Besancon, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comté, CNRS, Besancon, France","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","84","94","The Agile and DevOps transformation of software development practices enhances the need for increased automation of functional testing, especially for regression testing. This poses challenges both in the effort that needs to be devoted to the creation and maintenance of automated test scripts, and in their relevance (i.e. their alignment with business needs). Test automation is still difficult to implement and maintain and the return on investment comes late while projects tend to be short. In this context, we have experimented a lightweight model-based test automation approach to address both productivity and relevance challenges. It integrates test automation through a simple process and tool-chain experimented on large IT projects.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155866","","Automation;Tools;Unified modeling language;Testing;Software;Task analysis","program testing;software prototyping","lightweight MBT;software development practices;functional testing;regression testing;automated test scripts;lightweight model-based test automation approach;agile;DevOps transformation","","1","","10","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"New Techniques to Reduce the Execution Time of Functional Test Programs","M. Gaudesi; I. Pomeranz; M. S. Reorda; G. Squillero","Ominee, S.r.l., Via Carcano 26, Torino, Italy; Purdue University, West Lafayette, IN; Politecnico di Torino, Torino, Italy; Politecnico di Torino, Torino, Italy","IEEE Transactions on Computers","7 Jun 2017","2017","66","7","1268","1273","The compaction of test programs for processor-based systems is of utmost practical importance: Software-Based Self-Test (SBST) is nowadays increasingly adopted, especially for in-field test of safety-critical applications, and both the size and the execution time of the test are critical parameters. However, while compacting the size of binary test sequences has been thoroughly studied over the years, the reduction of the execution time of test programs is still a rather unexplored area of research. This paper describes a family of algorithms able to automatically enhance an existing test program, reducing the time required to run it and, as a side effect, its size. The proposed solutions are based on instruction removal and restoration, which is shown to be computationally more efficient than instruction removal alone. Experimental results demonstrate the compaction capabilities, and allow analyzing computational costs and effectiveness of the different algorithms.","1557-9956","","10.1109/TC.2016.2643663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795264","Software-based self-test;test compaction;test generation;test program","Compaction;Computational modeling;Clocks;Built-in self-test;Electronic mail;Algorithm design and analysis","microprocessor chips;program testing;safety-critical software","functional test programs;execution time;test programs;software based self-test;SBST;safety critical applications;compaction capabilities","","15","","44","IEEE","22 Dec 2016","","","IEEE","IEEE Journals"
"The practical aspects of TPS resource data discovery","L. V. Kirkland","Wes Test Engineering Corp., Farmington, Utah","2016 IEEE AUTOTESTCON","13 Oct 2016","2016","","","1","5","Performing a complete and accurate desktop analysis of a Test Program Set (TPS) with all the supporting data can be an extremely exhaustive experience. True TPS transparency has plagued the world of test and diagnosis for decades. Programs managers and users have a need to know exactly how the TPS works and how the Automatic Test Equipment (ATE) resources are allocated. It is fundamental to automatically make available a total envelope of TPS instrument usage and determine or make suggestions about TPS resource allocation considerations or facts. Exposing TPS facts which are somewhat hidden and providing guidance to aid in the determination of planning and support is important for process improvement. The evaluation of ATE resource allocation for a group of TPSs will aid in ATE design engineering. TPS resource transparency needs to be made available to all high level users and managers. Those who use a TPS and those who manage or oversee TPSs should have the resource data readily available to evaluate the TPS to know things like resource allocation usage and how the resources are used to expose TPS instrument requirements for future development and support. There are many pertinent and critical aspects which pertain to instrument settings and usage. Instrument or resource evaluation for a TPS is a much needed notion to judge test program performance and long term support. ATE resource utilization, selection, and recurrent problems of specific instruments, programming techniques or instrument settings can be revealed. There is a potential to refine the way a unit is tested, how resources are allocated and if resources can be optimized. Optimal resource allocation can potentially lower test time, solve TPS weaknesses, and keep current with technology to reduce long term support costs. An emulator can reveal run-time inefficiencies, range settings, limit levels, check program flow, allow assigning values to TPS variables, etc. The comprehensive information contained in the TPS and supporting data can serve to expose under and over utilized test equipment, proper resource selection, and many other issues which determine the quality of the TPS and ATE resources. Software programmable algorithms could expose facts automatically. A TPS developed by different engineers can and probably will utilize different instruments and/or instrument settings to perform some tests. The optimal use of instrumentation can be seen by RTOK rates, diagnostics, optimal measurements and glitches. There will always be some similarities in a TPS developed by different engineers but optimizing resource allocation is vital. To do an automated analysis of TPS resource usage data does provide valuable information but there can be questions about whether or not the TPS developer allocated the ATE resources properly or optimally. It is a fact, TPS developers vary in skill level and there can be profound differences in how resources are allocated. Relying on improperly allocated resources can produce superfluous results. This paper will cover the practical aspects of TPS Resource data. Also discussed is the availability of resource data and how to derive this data.","1558-4550","978-1-5090-0790-5","10.1109/AUTEST.2016.7589565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589565","","Instruments;Software;Resource management;Diffusion tensor imaging;Software algorithms;Dynamic scheduling;Pins","automatic test equipment;design engineering;program diagnostics;program testing;program verification;resource allocation","TPS resource data discovery;test program set desktop analysis;program testing;program diagnosis;automatic test equipment;ATE design engineering;TPS resource allocation;process improvement;optimal resource allocation;emulator;TPS comprehensive information;software programmable algorithms;RTOK rates;diagnostics;optimal measurements;glitches;automated analysis;TPS resource usage data","","","1","4","IEEE","13 Oct 2016","","","IEEE","IEEE Conferences"
"Mapping the Effectiveness of Automated Test Suite Generation Techniques","C. Oliveira; A. Aleti; L. Grunske; K. Smith-Miles","Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Humboldt University of Berlin, Germany; School of Mathematics and Statistics, The University of Melbourne, Melbourne, VIC, Australia","IEEE Transactions on Reliability","30 Aug 2018","2018","67","3","771","785","Automated test suite generation (ATSG) is an important topic in software engineering, with a wide range of techniques and tools being used in academia and industry. While their usefulness is widely recognized, due to the labor-intensive nature of the task, the effectiveness of the different techniques in automatically generating test cases for different software systems is not thoroughly understood. Despite many studies introducing various ATSG techniques, much remains to be learned, however, about what makes a particular technique work well (or not) for a specific software system. In this paper, we seek an answer to the question: “What features of a software system impact the effectiveness of ATSG techniques?” Once these features are identified, can they be used to select the most effective ATSG technique for a particular software system? To this end, we have implemented the mapping the effectiveness of test automation (META) tool, a new framework that identifies important software features that can be used to select suitable ATSG techniques to apply to new software systems. We evaluate the framework on a large set of open-source software projects and three ATSG techniques. The evaluation indicates that the number of methods in a class, the coupling between object classes, and the response for a class are the most indicative of what makes a software system hard to test by different techniques. The decision tree for ATSG technique selection generated by the META framework has an 88% accuracy, as shown by n-fold cross validation.","1558-1721","","10.1109/TR.2018.2832072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375677","Search-based software testing","Tools;Software systems;Automatic testing;Software testing","decision trees;program testing;public domain software;software engineering","automated test suite generation techniques;software engineering;automatically generating test cases;specific software system;software system impact;effective ATSG technique;particular software system;test automation tool;important software features;suitable ATSG techniques;open-source software projects","","18","","70","IEEE","8 Jun 2018","","","IEEE","IEEE Journals"
"Functional Dependency Detection for Integration Test Cases","S. Tahvili; M. Ahlberg; E. Fornander; W. Afzal; M. Saadatmand; M. Bohlin; M. Sarabi","Research Institutes of Sweden-RISE SICS Vasteras AB, Sweden; Royal Institute of Technology (KTH), Stockholm, Sweden; Kungliga Tekniska Hogskolan, Stockholm, SE; Mälardalen University, Västeras, Sweden; Research Institutes of Sweden-RISE SICS Vasteras AB, Sweden; Research Institutes of Sweden-RISE SICS Vasteras AB, Sweden; Bombardier Transportation AB, Vasteras, Sweden","2018 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)","13 Aug 2018","2018","","","207","214","This paper presents a natural language processing (NLP) based approach that, given software requirements specification, allows the functional dependency detection between integration test cases. We analyze a set of internal signals to the implemented modules for detecting dependencies between requirements and thereby identifying dependencies between test cases such that: module 2 depends on module 1 if an output internal signal from module 1 enters as an input internal signal to the module 2. Consequently, all requirements (and thereby test cases) for module 2 are dependent on all the designed requirements (and test cases) for module 1. The dependency information between requirements (and thus corresponding test cases) can be utilized for test case prioritization and scheduling. We have implemented our approach as a tool and the feasibility is evaluated through an industrial use case in the railway domain at Bombardier Transportation (BT), Sweden.","","978-1-5386-7839-8","10.1109/QRS-C.2018.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8431975","Software Testing;Dependency;Software Requirement;Internal Signals;NLP;Optimization","Testing;Software;Hardware;Natural language processing;Transportation;Job shop scheduling;Tools","formal specification;natural language processing;program testing;railway engineering;railways","functional dependency detection;integration test cases;natural language processing based approach;output internal signal;input internal signal;dependency information;test case prioritization;scheduling;industrial use case;software requirements specification;railway domain;Bombardier Transportation","","8","","26","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"On the Effectiveness of Manual and Automatic Unit Test Generation: Ten Years Later","D. Serra; G. Grano; F. Palomba; F. Ferrucci; H. C. Gall; A. Bacchelli","University of Salerno, Italy; University of Zurich, Switzerland; University of Zurich, Switzerland; University of Salerno, Italy; University of Zurich, Switzerland; University of Zurich, Switzerland","2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)","29 Aug 2019","2019","","","121","125","Good unit tests play a paramount role when it comes to foster and evaluate software quality. However, writing effective tests is an extremely costly and time consuming practice. To reduce such a burden for developers, researchers devised ingenious techniques to automatically generate test suite for existing code bases. Nevertheless, how automatically generated test cases fare against manually written ones is an open research question. In 2008, Bacchelli et.al. conducted an initial case study comparing automatic and manually generated test suites. Since in the last ten years we have witnessed a huge amount of work on novel approaches and tools for automatic test generation, in this paper we revise their study using current tools as well as complementing their research method by evaluating these tools' ability in finding regressions. Preprint [https://doi.org/10.5281/zenodo.2595232], dataset [https://doi.org/10.6084/m9.figshare.7628642].","2574-3864","978-1-7281-3412-3","10.1109/MSR.2019.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816768","Software Testing;Automatic Test Case Generation;Empirical Studies","Tools;Manuals;Production;Test pattern generators;Fault detection;Software","program testing;regression analysis;software quality;source code (software)","automatic unit test generation;software quality;code bases;automatic test generation;test case generation;manual unit test generation","","6","","28","IEEE","29 Aug 2019","","","IEEE","IEEE Conferences"
